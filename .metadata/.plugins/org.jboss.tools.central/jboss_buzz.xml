<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Automatic load balancing for PMD threads in Open vSwitch with DPDK</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/InvJnZZDzLo/" /><category term="Kubernetes" /><category term="Linux" /><category term="Performance" /><category term="load balancing" /><category term="Open vSwitch" /><category term="OpenStack" /><category term="ovs-dpdk" /><author><name>Kevin Traynor</name></author><id>https://developers.redhat.com/blog/?p=871477</id><updated>2021-04-29T07:00:51Z</updated><published>2021-04-29T07:00:51Z</published><content type="html">&lt;p&gt;This article is about the poll mode driver (PMD) automatic load balance feature in &lt;a target="_blank" rel="nofollow" href="https://docs.openvswitch.org/en/latest/intro/install/dpdk/"&gt;Open vSwitch with a Data Plane Development Kit&lt;/a&gt; data path (OVS-DPDK). The feature has existed for a while but we&amp;#8217;ve recently added new user parameters in Open vSwitch 2.15. Now is a good time to take a look at this feature in OVS-DPDK.&lt;/p&gt; &lt;p&gt;When you are finished reading this article, you will understand the problem the PMD auto load balance feature addresses and the user parameters required to operate it. Then, you can try it out for yourself.&lt;/p&gt; &lt;h2&gt;PMD threads in Open vSwitch with DPDK&lt;/h2&gt; &lt;p&gt;In the context of OVS-DPDK a &lt;em&gt;PMD thread&lt;/em&gt;, or &lt;em&gt;poll mode driver thread&lt;/em&gt;, is a thread that runs 1:1 on a dedicated core to continually poll ports for packets. When it receives packets, it processes and usually forwards them depending on the rules that the packets match.&lt;/p&gt; &lt;p&gt;Each PMD thread is assigned a group of Rx queues from the various ports attached to the OVS-DPDK bridges to poll. Typically, the ports are DPDK physical network interface controllers (NICs) and &lt;code&gt;vhost-user&lt;/code&gt; ports.&lt;/p&gt; &lt;p&gt;You can select how many and which cores are to be used for PMD threads. Increasing the number of cores makes more processing cycles available for packet processing, which can increase OVS-DPDK throughput.&lt;/p&gt; &lt;p&gt;For example, the following command selects cores 8 and 10 to be used by PMD threads:&lt;/p&gt; &lt;pre&gt;$ ovs-vsctl set Open_vSwitch . other_config:pmd-cpu-mask=0x500&lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: We will refer a lot to the &lt;em&gt;load&lt;/em&gt; of a PMD thread; this is the number of processing cycles the PMD thread uses for receiving and processing packets on its core.&lt;/p&gt; &lt;h2&gt;PMD threads and the packet processing load&lt;/h2&gt; &lt;p&gt;All Rx queues will not carry the same traffic, and some might have no traffic at all, so some PMD threads will do more packet processing than others. In other words, the packet processing load is not balanced across PMD threads.&lt;/p&gt; &lt;p&gt;In the worst case, some PMD threads could be overloaded processing packets while other PMD threads, possibly added to increase throughput, do nothing. In this scenario, some cores are not helping to increase the maximum possible throughput as their PMD threads have no useful work to do.&lt;/p&gt; &lt;p&gt;For example, in Figure 1, &lt;code&gt;dpdk0&lt;/code&gt; and &lt;code&gt;dpdk1&lt;/code&gt; ports have a lot of traffic and the PMD thread on core 8 is overloaded processing those packets. The &lt;code&gt;dpdk2&lt;/code&gt; and &lt;code&gt;dpdk3&lt;/code&gt; ports have no traffic and the PMD thread on core 10 is idle.&lt;/p&gt; &lt;div id="attachment_877517" style="width: 572px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/03/1-ovs-dpdk-overload-sketch.png"&gt;&lt;img aria-describedby="caption-attachment-877517" class="wp-image-877517 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2021/03/1-ovs-dpdk-overload-sketch.png" alt="The dpdk2 and dpdk3 threads have no traffic and the PMD thread on core 10 is idle." width="562" height="242" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/03/1-ovs-dpdk-overload-sketch.png 562w, https://developers.redhat.com/blog/wp-content/uploads/2021/03/1-ovs-dpdk-overload-sketch-300x129.png 300w" sizes="(max-width: 562px) 100vw, 562px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-877517" class="wp-caption-text"&gt;Figure 1: The packet processing load is not balanced across PMD threads.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Whenever there is a reconfiguration, such as adding new ports in OVS-DPDK, Rx queues are reassigned to PMD threads. The primary goal of reassigning is that the Rx queues requiring the most processing are assigned to different PMD threads, so as many PMD threads as possible get to do useful work.&lt;/p&gt; &lt;p&gt;But what happens if the load was not known during the last reconfiguration? Reasons might be that a port was just added, or traffic wasn’t started yet, or the load changed over time and there are no more reconfigurations. This is where the PMD auto load balance feature can help.&lt;/p&gt; &lt;h2&gt;PMD auto load balancing&lt;/h2&gt; &lt;p&gt;If the PMD auto load balance feature is enabled, it runs periodically. When a certain set of conditions are met, it triggers a reassignment of the Rx queues to PMD threads to improve the balance of load between the PMD threads.&lt;/p&gt; &lt;p&gt;These are the main conditions it checks as prerequisites:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;If any of the current PMD threads are very busy processing packets.&lt;/li&gt; &lt;li&gt;If the variance between the PMD thread loads is likely to improve after a reassignment.&lt;/li&gt; &lt;li&gt;If it is not too soon since the last reassignment.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;We can set exactly what constitutes &lt;em&gt;very busy&lt;/em&gt;, &lt;em&gt;improvement&lt;/em&gt;, and &lt;em&gt;too soon&lt;/em&gt; from the command line. We’ll see that when we look at the user parameters shortly.&lt;/p&gt; &lt;p&gt;The nice thing about this feature is that it will only do a reassignment if it detects that a PMD thread is currently very busy &lt;em&gt;and&lt;/em&gt; it estimates that there will be an improvement in variance after the reassignment. This helps to ensure we don’t have unnecessary reassignments.&lt;/p&gt; &lt;h2&gt;User parameters for PMD auto load balancing&lt;/h2&gt; &lt;p&gt;The PMD auto load balance feature is disabled by default. You can enable it at any time with:&lt;/p&gt; &lt;pre&gt;$ ovs-vsctl --no-wait set open_vSwitch . other_config:pmd-auto-lb="true"&lt;/pre&gt; &lt;p&gt;Let&amp;#8217;s look at the user parameters for this feature.&lt;/p&gt; &lt;h3&gt;Load threshold&lt;/h3&gt; &lt;p&gt;The &lt;em&gt;load threshold&lt;/em&gt; is the percentage of processing cycles one of the PMD threads must consistently be using for one minute before a reassignment can occur. The default is 95%. Since Open vSwitch 2.15, you can set this from the command line. To set it to 70%, you would enter the following:&lt;/p&gt; &lt;pre&gt;$ ovs-vsctl --no-wait set open_vSwitch . other_config:pmd-auto-lb-load-threshold="70"&lt;/pre&gt; &lt;h3&gt;Improvement threshold&lt;/h3&gt; &lt;p&gt;The &lt;em&gt;improvement threshold&lt;/em&gt; is the estimated improvement in load variance between the PMD threads that must be met before a reassignment can occur. To calculate the estimated improvement, a dry run of the reassignment is done and the estimated load variance is compared with the current variance. The default is 25%. Since Open vSwitch 2.15, you can set this from the command line. To set it to 50%, you would enter the following:&lt;/p&gt; &lt;pre&gt;$ ovs-vsctl --no-wait set open_vSwitch . other_config:pmd-auto-lb-improvement-threshold="50"&lt;/pre&gt; &lt;h3&gt;Interval threshold&lt;/h3&gt; &lt;p&gt;The &lt;em&gt;interval threshold&lt;/em&gt; is the minimum time in minutes between which two reassignments can be triggered. This is used to prevent triggering frequent reassignments where traffic patterns are changeable. For example, you might only want to trigger a reassignment once every 10 minutes or every few hours. The default is one minute; to set it to 10 minutes, you would enter:&lt;/p&gt; &lt;pre&gt;$ ovs-vsctl --no-wait set open_vSwitch . other_config:pmd-auto-lb-rebal-interval="10"&lt;/pre&gt; &lt;h2&gt;PMD auto load balancing in action&lt;/h2&gt; &lt;p&gt;Let’s revisit the simple example from Figure 1 to see the PMD auto load balance feature in action. As shown in Figure 2, we start with all traffic on one PMD thread on core 8 and no traffic on the PMD thread on core 10.&lt;/p&gt; &lt;div id="attachment_877517" style="width: 572px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/03/1-ovs-dpdk-overload-sketch.png"&gt;&lt;img aria-describedby="caption-attachment-877517" class="wp-image-877517 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2021/03/1-ovs-dpdk-overload-sketch.png" alt="The diagram shows that core 8 is overloaded, while core 10 has no traffic." width="562" height="242" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/03/1-ovs-dpdk-overload-sketch.png 562w, https://developers.redhat.com/blog/wp-content/uploads/2021/03/1-ovs-dpdk-overload-sketch-300x129.png 300w" sizes="(max-width: 562px) 100vw, 562px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-877517" class="wp-caption-text"&gt;Figure 2: One PMD thread on core 8 has all the traffic.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;We can check the Rx queue assignments with the following:&lt;/p&gt; &lt;pre&gt;$ ovs-appctl dpif-netdev/pmd-rxq-show&lt;/pre&gt; &lt;p&gt;The following output confirms that the PMD thread on core 8 has two active Rx queues while the PMD thread on core 10 has none:&lt;/p&gt; &lt;pre&gt;pmd thread numa_id 0 core_id 8: isolated : false port: dpdk0 queue-id: 0 (enabled) pmd usage: 47 % port: dpdk1 queue-id: 0 (enabled) pmd usage: 47 % pmd thread numa_id 0 core_id 10: isolated : false port: dpdk2 queue-id: 0 (enabled) pmd usage: 0 % port: dpdk3 queue-id: 0 (enabled) pmd usage: 0 % &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: The percentage usage shown for each Rx queue here is tightly measured around processing packets for individual Rx queues. It does not include any PMD thread operational overhead or time spent polling while getting no packets. Use &lt;code&gt;ovs-appctl dpif-netdev/pmd-stats-show&lt;/code&gt; to get more general PMD thread load totals.&lt;/p&gt; &lt;h3&gt;A case for reassignment&lt;/h3&gt; &lt;p&gt;At this point, the traffic generator indicates a maximum of 11 Mpps bi-directional throughput. This is certainly a case where the PMD auto load balance feature can help by triggering a reassignment. Following the reassignment, the PMD thread on core 10 should be utilized.&lt;/p&gt; &lt;p&gt;Let’s set some thresholds and enable the feature:&lt;/p&gt; &lt;pre&gt;$ ovs-vsctl set open_vSwitch . other_config:pmd-auto-lb-load-threshold="80" $ ovs-vsctl set open_vSwitch . other_config:pmd-auto-lb-improvement-threshold="50" $ ovs-vsctl set open_vSwitch . other_config:pmd-auto-lb-rebal-interval="1" $ ovs-vsctl set open_vSwitch . other_config:pmd-auto-lb="true" &lt;/pre&gt; &lt;p&gt;The logs confirm it has been enabled and the values we have set:&lt;/p&gt; &lt;pre&gt;|dpif_netdev|INFO|PMD auto load balance is enabled interval 1 mins, pmd load threshold 80%, improvement threshold 50%&lt;/pre&gt; &lt;p&gt;Soon, we see that a dry run has been completed and reconfiguration of the datapath has been requested to reassign the Rx queues to the PMD threads:&lt;/p&gt; &lt;pre&gt;|dpif_netdev|INFO|PMD auto lb dry run. requesting datapath reconfigure.&lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: You can get more detailed information about the operation and estimates in the &lt;code&gt;ovs-vswitchd.log&lt;/code&gt; file by enabling debug:&lt;/p&gt; &lt;pre style="padding-left: 40px;"&gt;$ ovs-appctl vlog/set dpif_netdev:file:dbg&lt;/pre&gt; &lt;h3&gt;Check the results&lt;/h3&gt; &lt;p&gt;Now, if we re-check the stats, we can confirm that the two Rx queues that are receiving packets are assigned to different PMD threads.&lt;/p&gt; &lt;pre&gt;pmd thread numa_id 0 core_id 8: isolated : false port: dpdk0 queue-id: 0 (enabled) pmd usage: 0 % port: dpdk2 queue-id: 0 (enabled) pmd usage: 88 % pmd thread numa_id 0 core_id 10: isolated : false port: dpdk1 queue-id: 0 (enabled) pmd usage: 88 % port: dpdk3 queue-id: 0 (enabled) pmd usage: 0 % &lt;/pre&gt; &lt;p&gt;We have gone from a situation where only one PMD thread was in use, to a case where both PMD threads are being utilized, as shown in Figure 3.&lt;/p&gt; &lt;div id="attachment_877567" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/03/4-ovs-dpdk-overunderload-horizontal-sketch.png"&gt;&lt;img aria-describedby="caption-attachment-877567" class="wp-image-877567 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/03/4-ovs-dpdk-overunderload-horizontal-sketch-1024x195.png" alt="The diagram shows a balanced traffic load." width="640" height="122" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/03/4-ovs-dpdk-overunderload-horizontal-sketch-1024x195.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/03/4-ovs-dpdk-overunderload-horizontal-sketch-300x57.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/03/4-ovs-dpdk-overunderload-horizontal-sketch-768x146.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2021/03/4-ovs-dpdk-overunderload-horizontal-sketch.png 1274w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-877567" class="wp-caption-text"&gt;Figure 3: Both PMD threads are fully utilized.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Checking the traffic generator, in this case, the throughput has risen from 11 Mpps with packet drops on both &lt;code&gt;dpdk0&lt;/code&gt; and &lt;code&gt;dpdk1&lt;/code&gt; ports to the maximum configured rate of 21 Mpps without any drops.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: In the example above, each port has one Rx queue, but in many cases, the workload can also be distributed with more granularity by using multiple Rx queues per port and RSS.&lt;/p&gt; &lt;h2&gt;Current limitations of PMD auto load balancing&lt;/h2&gt; &lt;p&gt;Of course, the example shown is a clear-cut case to illustrate the parameters and usage.&lt;/p&gt; &lt;p&gt;The reassignment code will assign the largest loaded Rx queues to different PMD threads. It will also try to ensure that all PMD threads have the same number of assigned Rx queues. This is to find a compromise between optimizing for the current traffic load and providing resilience for cases where traffic patterns might change and there is no PMD auto load balance.&lt;/p&gt; &lt;p&gt;In some cases, it is possible that assigning different numbers of Rx queues to PMD threads could give an even more improved balance for the current load. This is currently only available by &lt;a target="_blank" rel="nofollow" href="https://docs.openvswitch.org/en/latest/topics/dpdk/pmd/#port-rx-queue-assigment-to-pmd-threads"&gt;manual pinning&lt;/a&gt; and is an area for potential future optimizations.&lt;/p&gt; &lt;h2&gt;Wrap-up&lt;/h2&gt; &lt;p&gt;In this article, we’ve looked at the Open vSwitch with DPDK PMD auto load balance feature, the problem it helps to solve, and how it operates. The feature is taking shape and we&amp;#8217;ve added new user parameters in Open vSwitch 2.15. Feel free to try it out and give feedback on the ovs-discuss@openvswitch.org mailing list.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F29%2Fautomatic-load-balancing-for-pmd-threads-in-open-vswitch-with-dpdk%2F&amp;#38;linkname=Automatic%20load%20balancing%20for%20PMD%20threads%20in%20Open%20vSwitch%20with%20DPDK" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F29%2Fautomatic-load-balancing-for-pmd-threads-in-open-vswitch-with-dpdk%2F&amp;#38;linkname=Automatic%20load%20balancing%20for%20PMD%20threads%20in%20Open%20vSwitch%20with%20DPDK" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F29%2Fautomatic-load-balancing-for-pmd-threads-in-open-vswitch-with-dpdk%2F&amp;#38;linkname=Automatic%20load%20balancing%20for%20PMD%20threads%20in%20Open%20vSwitch%20with%20DPDK" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F29%2Fautomatic-load-balancing-for-pmd-threads-in-open-vswitch-with-dpdk%2F&amp;#38;linkname=Automatic%20load%20balancing%20for%20PMD%20threads%20in%20Open%20vSwitch%20with%20DPDK" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F29%2Fautomatic-load-balancing-for-pmd-threads-in-open-vswitch-with-dpdk%2F&amp;#38;linkname=Automatic%20load%20balancing%20for%20PMD%20threads%20in%20Open%20vSwitch%20with%20DPDK" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F29%2Fautomatic-load-balancing-for-pmd-threads-in-open-vswitch-with-dpdk%2F&amp;#38;linkname=Automatic%20load%20balancing%20for%20PMD%20threads%20in%20Open%20vSwitch%20with%20DPDK" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F29%2Fautomatic-load-balancing-for-pmd-threads-in-open-vswitch-with-dpdk%2F&amp;#38;linkname=Automatic%20load%20balancing%20for%20PMD%20threads%20in%20Open%20vSwitch%20with%20DPDK" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F29%2Fautomatic-load-balancing-for-pmd-threads-in-open-vswitch-with-dpdk%2F&amp;#038;title=Automatic%20load%20balancing%20for%20PMD%20threads%20in%20Open%20vSwitch%20with%20DPDK" data-a2a-url="https://developers.redhat.com/blog/2021/04/29/automatic-load-balancing-for-pmd-threads-in-open-vswitch-with-dpdk/" data-a2a-title="Automatic load balancing for PMD threads in Open vSwitch with DPDK"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/04/29/automatic-load-balancing-for-pmd-threads-in-open-vswitch-with-dpdk/"&gt;Automatic load balancing for PMD threads in Open vSwitch with DPDK&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/InvJnZZDzLo" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;This article is about the poll mode driver (PMD) automatic load balance feature in Open vSwitch with a Data Plane Development Kit data path (OVS-DPDK). The feature has existed for a while but we&amp;#8217;ve recently added new user parameters in Open vSwitch 2.15. Now is a good time to take a look at this feature [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/04/29/automatic-load-balancing-for-pmd-threads-in-open-vswitch-with-dpdk/"&gt;Automatic load balancing for PMD threads in Open vSwitch with DPDK&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/04/29/automatic-load-balancing-for-pmd-threads-in-open-vswitch-with-dpdk/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">871477</post-id><dc:creator>Kevin Traynor</dc:creator><dc:date>2021-04-29T07:00:51Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/04/29/automatic-load-balancing-for-pmd-threads-in-open-vswitch-with-dpdk/</feedburner:origLink></entry><entry><title>Containerize .NET for Red Hat OpenShift: Use a Windows VM like a container</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/T-IDo8msTQ8/" /><category term=".NET" /><category term="Containers" /><category term="Kubernetes" /><category term="Windows" /><category term="OpenShift Virtualization" /><category term="Windows containers" /><category term="Windows VM containers" /><author><name>Don Schenck</name></author><id>https://developers.redhat.com/blog/?p=885137</id><updated>2021-04-29T07:00:43Z</updated><published>2021-04-29T07:00:43Z</published><content type="html">&lt;p&gt;Embracing the future—making the transition from legacy monolithic applications running on .NET Framework to &lt;a target="_blank" rel="nofollow" href="/topics/microservices"&gt;microservices&lt;/a&gt; and images running in &lt;a target="_blank" rel="nofollow" href="/topics/containers"&gt;containers&lt;/a&gt; (or pods)—is a tall task. If only there were a safe, proceed-at-your-own-pace way to make the change, one that was familiar yet led to a new destination. Of course, there is such a path; otherwise, I wouldn&amp;#8217;t be writing this article. In this article, the last in my series introducing &lt;a target="_blank" rel="nofollow" href="/blog/2021/03/16/three-ways-to-containerize-net-applications-on-red-hat-openshift/"&gt;three ways to containerize .NET applications on Red Hat OpenShift&lt;/a&gt;, we&amp;#8217;ll look at running Windows virtual machines (VMs) on &lt;a target="_blank" rel="nofollow" href="/products/openshift/overview"&gt;OpenShift&lt;/a&gt;, and treating them like containers.&lt;/p&gt; &lt;p&gt;In case you missed them, here are the two other articles in the &amp;#8220;Containerize .NET for Red Hat OpenShift&amp;#8221; series:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="/blog/2021/04/22/containerize-net-for-red-hat-openshift-windows-containers-and-net-framework/"&gt;Windows containers and .NET Framework&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="/blog/2021/04/15/containerize-net-for-red-hat-openshift-linux-containers-and-net-core/"&gt;Linux containers and .NET Core&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;span id="more-885137"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Reframing &amp;#8216;legacy&amp;#8217; applications&lt;/h2&gt; &lt;p&gt;Apropos of nothing, I read an idea that I like, and it might help minimize the bad connotation that often comes with the phrase &amp;#8220;legacy application.&amp;#8221; All you have to do is replace the word &lt;em&gt;legacy&lt;/em&gt; with &lt;em&gt;proven&lt;/em&gt;. Nice, eh? Suddenly, you&amp;#8217;re not working on some old code that is barely doing the job. Instead, it&amp;#8217;s a proven system that is being upgraded with newer technology.&lt;/p&gt; &lt;p&gt;Okay, back to the topic at hand.&lt;/p&gt; &lt;h2&gt;Running Windows VMs on OpenShift&lt;/h2&gt; &lt;p&gt;Our goal is to run an existing &lt;a target="_blank" rel="nofollow" href="/blog/category/windows/"&gt;Windows&lt;/a&gt; virtual machine on OpenShift but treat it— from an operations perspective—as a container. We also want to keep the &amp;#8220;VM-ness&amp;#8221; that we&amp;#8217;re accustomed to, so we&amp;#8217;ll use the &lt;a target="_blank" rel="nofollow" href="https://www.openshift.com/learn/topics/virtualization/"&gt;OpenShift Virtualization Operator&lt;/a&gt;, which is built on &lt;a target="_blank" rel="nofollow" href="https://kubevirt.io/"&gt;KubeVirt technology&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;OpenShift Virtualization allows you to run a virtual machine (hint: it&amp;#8217;s not limited to Windows VMs) and have it appear within your cluster just how an image would. You get the same role-based access control, service discovery, and other features that you would with any image. Your web service running in IIS appears as &lt;em&gt;just another service&lt;/em&gt; in OpenShift. Your other applications can access it by service name; no ports, no IP addresses, no server names &amp;#8230; just the name.&lt;/p&gt; &lt;p&gt;And it works both ways: Your IIS website can access your other services by name. This could even include an SQL Server database.&lt;/p&gt; &lt;p&gt;Now I have your attention. Let&amp;#8217;s start setting up our development environment.&lt;/p&gt; &lt;h2&gt;Install the OpenShift Virtualization Operator&lt;/h2&gt; &lt;p&gt;The first step is to install the OpenShift Virtualization Operator. This is incredibly simple:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Search for and locate the OpenShift Virtualization Operator.&lt;/li&gt; &lt;li&gt;Click &lt;b&gt;Install&lt;/b&gt;.&lt;/li&gt; &lt;li&gt;Click &lt;b&gt;Install&lt;/b&gt; again.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Just like that, you&amp;#8217;ve installed the Operator. All that remains is to create a HyperConverged cluster:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Click &lt;b&gt;OpenShift Virtualization Deployment&lt;/b&gt;.&lt;/li&gt; &lt;li&gt;Click &lt;b&gt;Create HyperConverged&lt;/b&gt;.&lt;/li&gt; &lt;li&gt;Click &lt;b&gt;Create&lt;/b&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: &lt;a target="_blank" rel="nofollow" href="/blog/2020/08/28/enable-openshift-virtualization-on-red-hat-openshift/"&gt;This article&lt;/a&gt; has detailed instructions for installing the OpenShift Virtualization Operator.&lt;/p&gt; &lt;h2&gt;Install the virtctl CLI&lt;/h2&gt; &lt;p&gt;Life is easier if you use the command-line interface (CLI) tool, &lt;code&gt;virtctl&lt;/code&gt;. You can install it by following the &lt;a target="_blank" rel="nofollow" href="https://kubevirt.io/user-guide/operations/virtctl_client_tool/"&gt;instructions on this web page&lt;/a&gt;. The &lt;code&gt;virtctl&lt;/code&gt; CLI is handy for uploading virtual machine images into your cluster.&lt;/p&gt; &lt;h2&gt;Prepare the Hyper-V VM&lt;/h2&gt; &lt;p&gt;We&amp;#8217;ll use the &lt;a target="_blank" rel="nofollow" href="https://cloudbase.it/qemu-img-windows/"&gt;qemu-img command-line tool&lt;/a&gt; to convert the Hyper-V VM into QEMU copy-on-write (QCOW2) format. This is one of the formats that CNV is expecting. Here&amp;#8217;s the command I used:&lt;/p&gt; &lt;pre&gt;qemu-img convert "C:\Users\Public\Documents\Hyper-V\Virtual hard disks\win2012r2.vhdx" win2012r2.qcow2 -O qcow2 &lt;/pre&gt; &lt;p&gt;The conversion finished rather quickly on my machine. So quick, in fact, that I double-checked to make sure the output file was there. It&amp;#8217;s shown in Figure 1.&lt;/p&gt; &lt;div id="attachment_889397" style="width: 610px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/03/ls-output.png"&gt;&lt;img aria-describedby="caption-attachment-889397" class="wp-image-889397 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2021/03/ls-output.png" alt="Output of the LS command confirms the installation." width="600" height="139" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/03/ls-output.png 600w, https://developers.redhat.com/blog/wp-content/uploads/2021/03/ls-output-300x70.png 300w" sizes="(max-width: 600px) 100vw, 600px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-889397" class="wp-caption-text"&gt;Figure 1: The output file confirms the installation.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Once you have this 21GB file at hand, the fun begins.&lt;/p&gt; &lt;h2&gt;Upload the Hyper-V VM image to your cluster&lt;/h2&gt; &lt;p&gt;Uploading the Hyper-V VM image to a cluster turned out to be more of a project than I anticipated, but I came up with a workaround that I&amp;#8217;ll share with you here.&lt;/p&gt; &lt;p&gt;I&amp;#8217;ve uploaded and run scores of virtual machines. I typically use a smaller VM image, about 4GB, and it takes 45 minutes using my slow home internet. If something goes wrong, I wipe things out and start over; another hour or so lost.&lt;/p&gt; &lt;p&gt;Based on this experience, uploading a 21GB file would take hours, and I couldn&amp;#8217;t afford the time to upload it again if something went wrong. Knowing it was possible to pull a VM image into my cluster from a URL gave me a better idea.&lt;/p&gt; &lt;h2&gt;Amazon S3 to the rescue&lt;/h2&gt; &lt;p&gt;I decided to create a Simple Storage Service (S3) bucket in my Amazon Web Services account and upload my 21GB image to that. This would let me pull from the S3 URL straight into my cluster. AWS and Azure—where I&amp;#8217;m using &lt;a target="_blank" rel="nofollow" href="https://azure.microsoft.com/en-us/services/openshift/"&gt;Azure Red Hat OpenShift&lt;/a&gt; to host my cluster—both have super high-speed internet connections. Creating a VM should be quick.&lt;/p&gt; &lt;p&gt;It took four hours for my image to upload to the S3 bucket; I launched it in the evening and went to bed, fingers crossed that it would succeed, and it did.&lt;/p&gt; &lt;p&gt;In the end, it now takes about &lt;em&gt;four minutes&lt;/em&gt; to pull the image into my cluster. Software development isn&amp;#8217;t &lt;em&gt;always&lt;/em&gt; about failures; we have our winning moments, too. This was one of them, and I enjoyed it.&lt;/p&gt; &lt;h2&gt;Create the Windows VM in OpenShift&lt;/h2&gt; &lt;p&gt;Once the OpenShift container-native virtualization (CNV) &lt;em&gt;mise en place&lt;/em&gt; is ready, it&amp;#8217;s time to make things happen. Follow along with me here.&lt;/p&gt; &lt;p&gt;First, I logged in at the command-line and created my project, &lt;code&gt;winquotes&lt;/code&gt;, as shown in Figure 2.&lt;/p&gt; &lt;div id="attachment_889487" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/03/oc-new-project-winquotes.png"&gt;&lt;img aria-describedby="caption-attachment-889487" class="wp-image-889487" src="https://developers.redhat.com/blog/wp-content/uploads/2021/03/oc-new-project-winquotes.png" alt="Use the oc new-project command to create a new project." width="640" height="38" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/03/oc-new-project-winquotes.png 782w, https://developers.redhat.com/blog/wp-content/uploads/2021/03/oc-new-project-winquotes-300x18.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/03/oc-new-project-winquotes-768x46.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-889487" class="wp-caption-text"&gt;Figure 2: Create the project on the command line.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The remaining work happens in the Red Hat OpenShift administrator dashboard. To start, within the &lt;b&gt;winquotes&lt;/b&gt; project, I selected the &lt;b&gt;Virtualization&lt;/b&gt; option (shown in Figure 3) to start creating a new virtual machine.&lt;/p&gt; &lt;div id="attachment_889507" style="width: 563px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/03/winquotes-virtualization.png"&gt;&lt;img aria-describedby="caption-attachment-889507" class="wp-image-889507 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2021/03/winquotes-virtualization.png" alt="The virtualization option in the OpenShift project dashboard." width="553" height="437" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/03/winquotes-virtualization.png 553w, https://developers.redhat.com/blog/wp-content/uploads/2021/03/winquotes-virtualization-300x237.png 300w" sizes="(max-width: 553px) 100vw, 553px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-889507" class="wp-caption-text"&gt;Figure 3: Open the project and select the virtualization option.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The &lt;b&gt;New with Wizard&lt;/b&gt; option stepped me through the process, as shown in Figure 4.&lt;/p&gt; &lt;div id="attachment_889527" style="width: 426px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/03/virtualization-new-with-wizard.png"&gt;&lt;img aria-describedby="caption-attachment-889527" class="wp-image-889527 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2021/03/virtualization-new-with-wizard.png" alt="The virtualization 'New with wizard option' in OpenShift." width="416" height="338" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/03/virtualization-new-with-wizard.png 416w, https://developers.redhat.com/blog/wp-content/uploads/2021/03/virtualization-new-with-wizard-300x244.png 300w" sizes="(max-width: 416px) 100vw, 416px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-889527" class="wp-caption-text"&gt;Figure 4: Select the &amp;#8216;New with wizard&amp;#8217; option.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;As I mentioned in the last section, the VM instance is imported from the S3 URL. For demonstration purposes, I kept the CPU and RAM constraints low: 2GB of RAM and only two CPUs, as shown in Figure 5.&lt;/p&gt; &lt;div id="attachment_892467" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_general.png"&gt;&lt;img aria-describedby="caption-attachment-892467" class="wp-image-892467" src="https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_general.png" alt="The opening dialog for creating a new virtual machine." width="640" height="859" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_general.png 668w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_general-223x300.png 223w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-892467" class="wp-caption-text"&gt;Figure 5: Create a new virtual machine.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;It&amp;#8217;s important to edit the disk information, especially because the default value for the root disk is 15GB. The disk must be large enough to hold the original VM, which in my case had a 50GB drive. I edited the size to 60GB to be safe. I also changed the drive type to SATA because it&amp;#8217;s Windows. Figure 6 shows the default storage settings.&lt;/p&gt; &lt;div id="attachment_892477" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_storage_1.png"&gt;&lt;img aria-describedby="caption-attachment-892477" class="wp-image-892477" src="https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_storage_1.png" alt="Disk storage with default values." width="640" height="164" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_storage_1.png 818w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_storage_1-300x77.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_storage_1-768x197.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-892477" class="wp-caption-text"&gt;Figure 6: The default storage settings.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Figure 7 shows my edited storage settings.&lt;/p&gt; &lt;div id="attachment_892487" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_storage_2.png"&gt;&lt;img aria-describedby="caption-attachment-892487" class="wp-image-892487" src="https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_storage_2.png" alt="Disk storage values edited to support a Windows VM." width="640" height="241" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_storage_2.png 817w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_storage_2-300x113.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_storage_2-768x290.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-892487" class="wp-caption-text"&gt;Figure 7: The edited storage settings.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;I was able to go with the default values on the screen for the remainder of the process to create this virtual machine. When I reached the final screen, it immediately began importing the VM located at the supplied S3 URL, as shown in Figure 8.&lt;/p&gt; &lt;div id="attachment_892527" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_importing.png"&gt;&lt;img aria-describedby="caption-attachment-892527" class="wp-image-892527" src="https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_importing.png" alt="The VM import is automatic." width="640" height="262" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_importing.png 807w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_importing-300x123.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_importing-768x314.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-892527" class="wp-caption-text"&gt;Figure 8: Importing the virtual machine.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;When the import was finished, the VM was turned off, as shown in Figure 9.&lt;/p&gt; &lt;div id="attachment_893517" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_status_off.png"&gt;&lt;img aria-describedby="caption-attachment-893517" class="wp-image-893517" src="https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_status_off.png" alt="The VM status is off." width="640" height="233" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_status_off.png 770w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_status_off-300x109.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_status_off-768x279.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-893517" class="wp-caption-text"&gt;Figure 9: The virtual machine status is off.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;I started it from the menu in the upper-right corner, as shown in Figure 10.&lt;/p&gt; &lt;div id="attachment_892547" style="width: 200px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_start_menu_option.png"&gt;&lt;img aria-describedby="caption-attachment-892547" class="wp-image-892547 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_start_menu_option.png" alt="Select the option to start the virtual machine." width="190" height="288" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-892547" class="wp-caption-text"&gt;Figure 10: Start the virtual machine manually.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;I then switched to OpenShift&amp;#8217;s console view and waited for my login screen. As shown in Figure 11, my Windows VM was up and running in OpenShift.&lt;/p&gt; &lt;div id="attachment_893507" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_log_on-1.png"&gt;&lt;img aria-describedby="caption-attachment-893507" class="wp-image-893507 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_log_on-1-1024x562.png" alt="The Windows VM login screen." width="640" height="351" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_log_on-1-1024x562.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_log_on-1-300x165.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_log_on-1-768x422.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_log_on-1.png 1433w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-893507" class="wp-caption-text"&gt;Figure 11: The virtual machine has started.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;I then went to open the IIS application in my browser and &lt;code&gt;localhost:8081/api/quotes&lt;/code&gt;, expecting to see it working. But it wasn&amp;#8217;t working. The application could not connect to the database running in Azure.&lt;/p&gt; &lt;p&gt;As it turns out, the VM cannot connect to the network until the VirtIO network driver is installed.&lt;/p&gt; &lt;h2&gt;How to install the VirtIO network driver&lt;/h2&gt; &lt;p&gt;If you&amp;#8217;ve followed along with me so far, you can go into your CD drive and install the guest tools, including the VirtIO driver. After that, your application will be connected to the internet. Figure 12 shows the Windows file explorer with the CD ROM listed.&lt;/p&gt; &lt;div id="attachment_893497" style="width: 567px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_drives.png"&gt;&lt;img aria-describedby="caption-attachment-893497" class="wp-image-893497 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_drives.png" alt="Windows file explorer showing the CD drive." width="557" height="306" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_drives.png 557w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_drives-300x165.png 300w" sizes="(max-width: 557px) 100vw, 557px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-893497" class="wp-caption-text"&gt;Figure 12: Windows file explorer showing the VirtIO driver.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Now, your service should be able to reach your database, and it should be up and running. The next step is to convert the service into an OpenShift service and make it available to other applications within your cluster.&lt;/p&gt; &lt;h2&gt;Create and expose a service within a cluster&lt;/h2&gt; &lt;p&gt;We want to expose the application as a service within a cluster, which starts with creating a service. The command-line tool, &lt;code&gt;virtctl&lt;/code&gt;, is useful for this purpose. For my example, I specified the name of the VM, the port I wanted to expose—8081 in my case—and assigned a name to the service. I used the following command to do all that:&lt;/p&gt; &lt;pre&gt;virtctl expose vm quotesvm --port=8081 --name=quotes --type=NodePort &lt;/pre&gt; &lt;p&gt;Now, we have a service that is available by name (&amp;#8220;quotes,&amp;#8221; in this case) within the cluster. A service. Running in an OpenShift cluster. Running on IIS. Inside a Windows VM.&lt;/p&gt; &lt;p&gt;Mind, blown.&lt;/p&gt; &lt;p&gt;Finally, just like any other service within a cluster, we can use OpenShift&amp;#8217;s &lt;code&gt;oc&lt;/code&gt; command to expose this service to the world, as shown in Figure 13.&lt;/p&gt; &lt;div id="attachment_892677" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_expose_service.png"&gt;&lt;img aria-describedby="caption-attachment-892677" class="wp-image-892677" src="https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_expose_service.png" alt="Enter 'oc expose service quotes' to expose the service." width="640" height="64" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_expose_service.png 966w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_expose_service-300x30.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_expose_service-768x77.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-892677" class="wp-caption-text"&gt;Figure 13: Expose the service on the command line.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Now, we should be able to open a browser in any internet-connected machine and see the service results at the URL listed. Except, it doesn&amp;#8217;t work.&lt;/p&gt; &lt;p&gt;Why not?&lt;/p&gt; &lt;h2&gt;A VM is a VM is a VM&lt;/h2&gt; &lt;p&gt;Let&amp;#8217;s go back to the VM. Even though everything inside our cluster is aligned and configured correctly, the VM still needs a new Windows firewall rule to access port 8081. Don&amp;#8217;t forget: It&amp;#8217;s still a virtual machine and acts like one. You can manage and treat this VM like an OpenShift application in the context of OpenShift, but the underlying technology is still a VM. Adjust accordingly.&lt;/p&gt; &lt;p&gt;Once we establish the new firewall rule, we have success. Our service is available to the world. Figure 14 shows the service on my phone (a Surface Duo, by the way).&lt;/p&gt; &lt;div id="attachment_892717" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_running_on_phone.png"&gt;&lt;img aria-describedby="caption-attachment-892717" class="wp-image-892717" src="https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_running_on_phone.png" alt="A mobile phone web browser showing the running service." width="640" height="890" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_running_on_phone.png 727w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/create_vm_running_on_phone-216x300.png 216w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-892717" class="wp-caption-text"&gt;Figure 14: The live service on a mobile phone browser.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Conclusion: What are you waiting for?&lt;/h2&gt; &lt;p&gt;You can run Windows VMs in Red Hat OpenShift and treat them like containers. You can &lt;a target="_blank" rel="nofollow" href="/blog/2021/04/22/containerize-net-for-red-hat-openshift-windows-containers-and-net-framework/"&gt;run Windows applications in Windows containers on OpenShift&lt;/a&gt;. You can &lt;a target="_blank" rel="nofollow" href="/blog/2021/04/15/containerize-net-for-red-hat-openshift-linux-containers-and-net-core/"&gt;create Linux containers using .NET Core&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;There are no blockers. You have the tools. Embrace the future.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F29%2Fcontainerize-net-for-red-hat-openshift-use-a-windows-vm-like-a-container%2F&amp;#38;linkname=Containerize%20.NET%20for%20Red%20Hat%20OpenShift%3A%20Use%20a%20Windows%20VM%20like%20a%20container" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F29%2Fcontainerize-net-for-red-hat-openshift-use-a-windows-vm-like-a-container%2F&amp;#38;linkname=Containerize%20.NET%20for%20Red%20Hat%20OpenShift%3A%20Use%20a%20Windows%20VM%20like%20a%20container" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F29%2Fcontainerize-net-for-red-hat-openshift-use-a-windows-vm-like-a-container%2F&amp;#38;linkname=Containerize%20.NET%20for%20Red%20Hat%20OpenShift%3A%20Use%20a%20Windows%20VM%20like%20a%20container" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F29%2Fcontainerize-net-for-red-hat-openshift-use-a-windows-vm-like-a-container%2F&amp;#38;linkname=Containerize%20.NET%20for%20Red%20Hat%20OpenShift%3A%20Use%20a%20Windows%20VM%20like%20a%20container" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F29%2Fcontainerize-net-for-red-hat-openshift-use-a-windows-vm-like-a-container%2F&amp;#38;linkname=Containerize%20.NET%20for%20Red%20Hat%20OpenShift%3A%20Use%20a%20Windows%20VM%20like%20a%20container" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F29%2Fcontainerize-net-for-red-hat-openshift-use-a-windows-vm-like-a-container%2F&amp;#38;linkname=Containerize%20.NET%20for%20Red%20Hat%20OpenShift%3A%20Use%20a%20Windows%20VM%20like%20a%20container" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F29%2Fcontainerize-net-for-red-hat-openshift-use-a-windows-vm-like-a-container%2F&amp;#38;linkname=Containerize%20.NET%20for%20Red%20Hat%20OpenShift%3A%20Use%20a%20Windows%20VM%20like%20a%20container" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F29%2Fcontainerize-net-for-red-hat-openshift-use-a-windows-vm-like-a-container%2F&amp;#038;title=Containerize%20.NET%20for%20Red%20Hat%20OpenShift%3A%20Use%20a%20Windows%20VM%20like%20a%20container" data-a2a-url="https://developers.redhat.com/blog/2021/04/29/containerize-net-for-red-hat-openshift-use-a-windows-vm-like-a-container/" data-a2a-title="Containerize .NET for Red Hat OpenShift: Use a Windows VM like a container"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/04/29/containerize-net-for-red-hat-openshift-use-a-windows-vm-like-a-container/"&gt;Containerize .NET for Red Hat OpenShift: Use a Windows VM like a container&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/T-IDo8msTQ8" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Embracing the future—making the transition from legacy monolithic applications running on .NET Framework to microservices and images running in containers (or pods)—is a tall task. If only there were a safe, proceed-at-your-own-pace way to make the change, one that was familiar yet led to a new destination. Of course, there is such a path; otherwise, [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/04/29/containerize-net-for-red-hat-openshift-use-a-windows-vm-like-a-container/"&gt;Containerize .NET for Red Hat OpenShift: Use a Windows VM like a container&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/04/29/containerize-net-for-red-hat-openshift-use-a-windows-vm-like-a-container/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">885137</post-id><dc:creator>Don Schenck</dc:creator><dc:date>2021-04-29T07:00:43Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/04/29/containerize-net-for-red-hat-openshift-use-a-windows-vm-like-a-container/</feedburner:origLink></entry><entry><title>Enhance application security by rotating 3scale access tokens</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Wj_HqsUyFeU/" /><category term="DevOps" /><category term="Kubernetes" /><category term="Security" /><category term="3scale access tokens" /><category term="3scale API Management" /><category term="API-Management" /><author><name>Samuele Illuminati</name></author><id>https://developers.redhat.com/blog/?p=805527</id><updated>2021-04-29T07:00:08Z</updated><published>2021-04-29T07:00:08Z</published><content type="html">&lt;p&gt;In &lt;a target="_blank" rel="nofollow" href="/products/3scale/overview"&gt;Red Hat 3scale API Management&lt;/a&gt;, &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_3scale/2-saas/html/admin_portal_guide/tokens"&gt;access tokens&lt;/a&gt; allow authentication against the 3scale APIs. An access token can provide read and write access to the Billing, Account Management, and Analytics APIs. Therefore, ensuring you are handling access tokens carefully is paramount.&lt;/p&gt; &lt;p&gt;This article explains how to enhance security by making access tokens ephemeral. By the end of the article, you will be able to set up 3scale to perform access token rotation. An external webhook listener service performs the actual token revocation. The rotation takes place automatically after a specific event triggers a webhook.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: This article does &lt;em&gt;not&lt;/em&gt; cover access tokens used with the 3scale gateway as part of any OAuth or OpenID Connect flows.&lt;/p&gt; &lt;h2&gt;A step-by-step guide to access token rotation&lt;/h2&gt; &lt;p&gt;Example scenario: I want single-use access tokens so that after the token is used for creating an application via the 3scale API, it will automatically be revoked.&lt;/p&gt; &lt;h3&gt;Prerequisites&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://www.3scale.net/"&gt;Red Hat 3scale API Management 2.8 on-premises or later, or Red Hat 3scale API Management SaaS&lt;/a&gt;&lt;/li&gt; &lt;li style="font-weight: 400;"&gt;A webhook listener service (you can use &lt;a target="_blank" rel="nofollow" href="https://github.com/samugi/3scale-AccessTokenRevoker/tree/demo"&gt;this&lt;/a&gt; for the tutorial)&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;Setting up the access tokens&lt;/h3&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: It is important to complete the following steps before proceeding to the &amp;#8220;End-to-end flow in action&amp;#8221; section.&lt;/p&gt; &lt;p&gt;For this tutorial, you can use the example application &lt;a target="_blank" rel="nofollow" href="https://github.com/samugi/3scale-AccessTokenRevoker/tree/demo"&gt;AccessTokenRevoker&lt;/a&gt;. However, it’s recommended to implement your own webhook listener service in your preferred language for a real-world scenario.&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_3scale_api_management/2.9/html/creating_the_developer_portal/custom-signup-fields"&gt;Create a custom field definition&lt;/a&gt; on the Application object and make it &lt;em&gt;hidden&lt;/em&gt;. Set the &lt;strong&gt;Name&lt;/strong&gt; and &lt;strong&gt;Label&lt;/strong&gt; fields, as shown in Figure 1. For this example, we will use &lt;code&gt;token_ value&lt;/code&gt; and &lt;code&gt;Token Value&lt;/code&gt;, respectively. The &lt;strong&gt;Name&lt;/strong&gt; field is important here because that is the parameter that will be parsed from the webhook object later. &lt;p&gt;&lt;div id="attachment_806737" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/tokenvalue.png"&gt;&lt;img aria-describedby="caption-attachment-806737" class="wp-image-806737" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/tokenvalue.png" alt="The custom sign-up form fields; Name and Label are defined and the Hidden checkbox is selected." width="640" height="271" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/tokenvalue.png 925w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/tokenvalue-300x127.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/tokenvalue-768x325.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-806737" class="wp-caption-text"&gt;Figure 1: Defining the custom sign-up form fields.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_3scale_api_management/2.9/html/creating_the_developer_portal/webhooks#introducing_webhooks"&gt;Configure 3scale webhooks&lt;/a&gt; to deliver upon admin portal actions, specifically for the&lt;strong&gt; Application created&lt;/strong&gt; event, as shown in Figure 2. &lt;p&gt;&lt;div id="attachment_805577" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/webhook_config.png"&gt;&lt;img aria-describedby="caption-attachment-805577" class="wp-image-805577" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/webhook_config.png" alt="3scale webhooks configuration; the Application created checkbox is selected." width="640" height="352" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/webhook_config.png 1572w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/webhook_config-300x165.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/webhook_config-768x423.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/webhook_config-1024x563.png 1024w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-805577" class="wp-caption-text"&gt;Figure 2: Configure 3scale webhooks.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt; &lt;li&gt;Deploy an application running as an external service to 3scale where the 3scale webhooks will be delivered and parsed; the application will subsequently make an API call to 3scale to rotate the access token. See the &lt;a target="_blank" rel="nofollow" href="https://github.com/samugi/3scale-AccessTokenRevoker/blob/demo/README.md"&gt;example application instructions&lt;/a&gt; to deploy and configure the application to follow along with the steps.Here is an example command that you can use to start the example application: &lt;pre&gt;node app.js --url "https://{TENANT | ACCOUNT}-admin.{WILDCARD_DOMAIN | 3scale.net}" &lt;/pre&gt; &lt;/li&gt; &lt;li&gt;The API call to 3scale should pass the value of the custom field &lt;strong&gt;Token Value&lt;/strong&gt; as both the &lt;code&gt;access_token&lt;/code&gt; and &lt;code&gt;id&lt;/code&gt; parameters to the Personal Access Token Delete API.Here is an example of a curl request the application should implement to revoke the token successfully: &lt;pre&gt;curl -X DELETE "https://{TENANT | ACCOUNT}-admin.{WILDCARD_DOMAIN | 3scale.net}/admin/api/personal/access_tokens/${ACCESS_TOKEN}.json" -d 'access_token=${ACCESS_TOKEN}'&lt;/pre&gt; &lt;/li&gt; &lt;/ol&gt; &lt;h2&gt;End-to-end flow in action&lt;/h2&gt; &lt;ol&gt; &lt;li&gt;The admin user &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_3scale_api_management/2.9/html/admin_portal_guide/tokens#creating-access-tokens"&gt;creates an access token&lt;/a&gt; with read/write permissions and scope for the Account Management API.&lt;/li&gt; &lt;li&gt;The user creates an application from the 3scale API and is required to add a value to the field created in the &amp;#8220;Setting up the access token&amp;#8221; section. The value of this field should be equal to the access token created in step 1.The following is an example of a curl request to the 3scale API. You can use this to create a new application and rotate the token. Notice the &lt;code&gt;token_value&lt;/code&gt; field contains the access token as a value in the request’s POST data: &lt;pre&gt;curl -X POST "https://{TENANT | ACCOUNT}-admin.{WILDCARD_DOMAIN | 3scale.net}/admin/api/accounts/${ACCOUNT_ID}/applications.xml" -d 'access_token=${ACCESS_TOKEN}&amp;#38;plan_id=${PLAN_ID}&amp;#38;name=${APPLICATION_NAME}&amp;#38;description=demo&amp;#38;token_value=${ACCESS_TOKEN}' &lt;/pre&gt; &lt;/li&gt; &lt;li&gt;The &lt;strong&gt;Application created&lt;/strong&gt; event triggers the 3scale webhook. Figure 3 is an example of what the webhook’s request body looks like. The token value is visible as part of the extra_fields object in &lt;code&gt;req.body.event.object[0].application[0].extra_fields[0].token_value[0]&lt;/code&gt;. &lt;p&gt;&lt;div id="attachment_805627" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/object.png"&gt;&lt;img aria-describedby="caption-attachment-805627" class="wp-image-805627" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/object.png" alt="Sample body for a webhook's request." width="640" height="446" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/object.png 958w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/object-300x209.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/object-768x536.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-805627" class="wp-caption-text"&gt;Figure 3: Webhook&amp;#8217;s request body.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt; &lt;li&gt;The external service listening for 3scale webhooks receives this object. It then parses the body for the custom field defined previously. In the example, the value of &lt;code&gt;token_value&lt;/code&gt; is stored for the API call to 3scale.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Once the token has been deleted, it will no longer function. Cleaning it up from the &lt;code&gt;hidden&lt;/code&gt; field on the application is optional at this point, given that the field is hidden and no longer valid.&lt;/p&gt; &lt;p&gt;Alternatively, in the setup phase, you can set the custom field definition to &lt;code&gt;required&lt;/code&gt; instead of &lt;code&gt;hidden&lt;/code&gt;. This prevents the user from creating an application without setting this important field. This way, the custom field is visible by default to developers if they have access to the developer portal. This can pose a security threat while the access token is still valid. As a further step, you can ensure that the field doesn&amp;#8217;t render in HTML by customizing the liquid templates in the developer portal.&lt;/p&gt; &lt;h2&gt;Supported webhook event triggers&lt;/h2&gt; &lt;p&gt;It is possible to configure this workflow to fit the API provider&amp;#8217;s requirements to rotate tokens after any of the supported webhook event triggers shown in Figure 4.&lt;/p&gt; &lt;div id="attachment_805637" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/webhook_events.png"&gt;&lt;img aria-describedby="caption-attachment-805637" class="wp-image-805637" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/webhook_events.png" alt="Events that trigger webhooks are listed under the categories Accounts, Users, Applications, and Keys." width="640" height="175" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/webhook_events.png 1385w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/webhook_events-300x82.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/webhook_events-768x210.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/webhook_events-1024x280.png 1024w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-805637" class="wp-caption-text"&gt;Figure 4: Events that trigger webhooks.&lt;/p&gt;&lt;/div&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: Remember that webhooks will be triggered for the same events that occur due to actions executed from the Developer portal.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In this article, you learned how 3scale users can use temporary access tokens to access all the features available via the 3scale API, keeping security in mind. Feel free to comment on this article with any suggestions for how to improve this content.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F29%2Fenhance-application-security-by-rotating-3scale-access-tokens%2F&amp;#38;linkname=Enhance%20application%20security%20by%20rotating%203scale%20access%20tokens" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F29%2Fenhance-application-security-by-rotating-3scale-access-tokens%2F&amp;#38;linkname=Enhance%20application%20security%20by%20rotating%203scale%20access%20tokens" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F29%2Fenhance-application-security-by-rotating-3scale-access-tokens%2F&amp;#38;linkname=Enhance%20application%20security%20by%20rotating%203scale%20access%20tokens" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F29%2Fenhance-application-security-by-rotating-3scale-access-tokens%2F&amp;#38;linkname=Enhance%20application%20security%20by%20rotating%203scale%20access%20tokens" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F29%2Fenhance-application-security-by-rotating-3scale-access-tokens%2F&amp;#38;linkname=Enhance%20application%20security%20by%20rotating%203scale%20access%20tokens" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F29%2Fenhance-application-security-by-rotating-3scale-access-tokens%2F&amp;#38;linkname=Enhance%20application%20security%20by%20rotating%203scale%20access%20tokens" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F29%2Fenhance-application-security-by-rotating-3scale-access-tokens%2F&amp;#38;linkname=Enhance%20application%20security%20by%20rotating%203scale%20access%20tokens" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F29%2Fenhance-application-security-by-rotating-3scale-access-tokens%2F&amp;#038;title=Enhance%20application%20security%20by%20rotating%203scale%20access%20tokens" data-a2a-url="https://developers.redhat.com/blog/2021/04/29/enhance-application-security-by-rotating-3scale-access-tokens/" data-a2a-title="Enhance application security by rotating 3scale access tokens"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/04/29/enhance-application-security-by-rotating-3scale-access-tokens/"&gt;Enhance application security by rotating 3scale access tokens&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Wj_HqsUyFeU" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;In Red Hat 3scale API Management, access tokens allow authentication against the 3scale APIs. An access token can provide read and write access to the Billing, Account Management, and Analytics APIs. Therefore, ensuring you are handling access tokens carefully is paramount. This article explains how to enhance security by making access tokens ephemeral. By the [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/04/29/enhance-application-security-by-rotating-3scale-access-tokens/"&gt;Enhance application security by rotating 3scale access tokens&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/04/29/enhance-application-security-by-rotating-3scale-access-tokens/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">805527</post-id><dc:creator>Samuele Illuminati</dc:creator><dc:date>2021-04-29T07:00:08Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/04/29/enhance-application-security-by-rotating-3scale-access-tokens/</feedburner:origLink></entry><entry><title type="html">Store health and safety - Example health and safety architecture</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/kfw7sucst04/store-health-and-safety-example-health-and-safety-architecture.html" /><author><name>Eric D. Schabell</name></author><id>http://feedproxy.google.com/~r/schabell/jboss/~3/Im-HB84o2sA/store-health-and-safety-example-health-and-safety-architecture.html</id><updated>2021-04-29T05:00:00Z</updated><content type="html">Part 3 - Example store health and safety architecture In our  from this series shared a look at the logical common architectural elements found in a store health and safety solution for retail organisations. The process was laid out how we've approached the use case and how portfolio solutions are the base for researching a generic architectural blueprint. It continued by laying out the process of how we've approached the use case by researching successful customer portfolio solutions as the basis for a generic architectural blueprint. Having completed our discussions on the logical view of the blueprint, it's now time to look at a specific example. This article walks you through an example store health and safety scenario showing how expanding the previously discussed elements provides a blueprint for your own store health and safety scenarios. BLUEPRINTS REVIEW As mentioned before, the architectural details covered here are base on real solutions using open source technologies. The example scenario presented here is a generic common blueprint that was uncovered researching those solutions. It's our intent to provide a blueprint that provides guidance and not deep technical details. This section covers the visual representations as presented, but it's expected that they'll be evolving based on future research. There are many ways to represent each element in this architectural blueprint, but we've chosen a format that we hope makes it easy to absorb. Feel free to post comments at the bottom of this post, or  with your feedback. Now let's take a look at the details in this blueprint and outline the solution for two views of the store health and safety architecture solution. STORE HEALTH AND SAFETY The first look is of the overal architecture for store health and safety with details filled in that were discussed as logical elements previously. Starting on the right there are two entry points for the array of actors you can expect for this use case. One group is requesting actions of your health and safety architecture; suppliers, customers, colleagues / associates, and a catch-all others group. The second are actors that are completing assigned user tasks from the various store processes or health and safety processes; customers and suppliers.  All these actors are provided applications that access the architecture through API management to ensure proper authentication and authorisation before processing their requests. A closer look at this architecture blueprint reveals that the main focus is centred around process automation and decision management. Both are clear winners for the management of rules, compliancy, and for creating consistency across the organisation with regards to health and safety management. The first collection of business automation processes is found in the store processes, a collection of processes designed a a more generic level. To provide clarity and simplicity in this architecture blueprint, the supporting second level of process automation capturing health and safety processes.  Within the various processes there is always a need for validation, business rules, and compliancy with regards to health and safety laws that can be vastly different depending on your country or even region of operations. To that end, the local store rules and health and safety rules are collections designed to ensure standardisation and compliancy across the processes you've designed for your retail organisation. Backing the various processes are collections of microservices that support connectivity and interactions with the various internal and external systems. The supplier microservices would be leveraged from processes and process information through to the backend systems as needed leveraging integration microservices specifically to directly connect to specific systems. Integration data microservices are used to ensure that the interactions with the Retail Data Framework remain consistent to ensure other areas of your retail architecture are supported (for example Real-time Stock Control) with up to date data. Finally, there are three externally located systems; internal remote systems which are managed but the retail organisation, external systems managed by third-party vendors, and internal local systems. All of these constitute the backend systems for the retail organisation. Next up, a look at the architectural solution with a focus on the data view. STORE HEALTH AND SAFETY DATA Data connectivity through the store health and safety architecture provides a different look at the architecture and gives us insights into how the most valuable asset of a retail organisation is being processed. It should be seen as the blueprint is intended, as a guide and not a definitive must-do-it-this-way statement on how the data is being routed through as actors on the front end are engaging with the systems, processes, and microservices in this architecture. Note that many of the data flows only one direction while it's fairly obvious it's going to flow both ways. We've chosen to note that in the flows that do not disrupt the clarity of the architecture diagram, and chose not to indicate that where the intent is to show processing and flows for clarity from actors to systems on the backend. It's left to the reader to explore this data diagrams and feel free to send comments our way. WHAT'S NEXT This was just a short overview of the common generic elements that make up our architecture blueprint for the store health and safety use case.  An overview of this series on store health and safety portfolio architecture blueprint: 1. 2. 3. Catch up on any articles you missed by following one of the links above. This completes the series and we hope you enjoyed this architecture blueprint for store health and safety in retail. (Article co-authored by , Chief Architect Retail, Red Hat)&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/kfw7sucst04" height="1" width="1" alt=""/&gt;</content><dc:creator>Eric D. Schabell</dc:creator><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/Im-HB84o2sA/store-health-and-safety-example-health-and-safety-architecture.html</feedburner:origLink></entry><entry><title>Kubernetes configuration patterns, Part 1: Patterns for Kubernetes primitives</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/b0j_RiD9TMo/" /><category term="Containers" /><category term="Kubernetes" /><category term="Machine Learning" /><category term="configmap" /><category term="Kubernetes configuration patterns" /><category term="Kubernetes primitives" /><category term="secrets" /><author><name>Ali Ok</name></author><id>https://developers.redhat.com/blog/?p=824267</id><updated>2021-04-28T07:00:45Z</updated><published>2021-04-28T07:00:45Z</published><content type="html">&lt;p&gt;This article is the first in a two-part article series on &lt;a target="_blank" rel="nofollow" href="/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; configuration patterns, which represent ways of configuring Kubernetes applications and controllers. Part 1 introduces simple approaches that use only Kubernetes primitives. These patterns are applicable to any application running on Kubernetes. Part 2 will introduce more advanced patterns. These patterns require you to code against the Kubernetes API when you are developing Kubernetes controllers.&lt;/p&gt; &lt;p style="padding-left: 40px"&gt;&lt;strong&gt;Note&lt;/strong&gt;: &lt;em&gt;Kubernetes controllers&lt;/em&gt; are programs that run on Kubernetes and manage resources in Kubernetes.&lt;/p&gt; &lt;p&gt;For simplicity, I&amp;#8217;ve used only &lt;code&gt;Deployment&lt;/code&gt;s in the example YAML files. However, the examples should work with other &lt;code&gt;PodSpecable&lt;/code&gt;s (anything that describes a &lt;code&gt;PodSpec&lt;/code&gt;) such as &lt;code&gt;DaemonSet&lt;/code&gt;s and &lt;code&gt;ReplicaSet&lt;/code&gt;s. I also omitted fields like &lt;code&gt;image&lt;/code&gt;, &lt;code&gt;imagePullPolicy&lt;/code&gt;, and others in the example &lt;code&gt;Deployment&lt;/code&gt; YAML.&lt;/p&gt; &lt;h2&gt;Configuration with command-line arguments&lt;a name="basics_1"&gt;&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;Kubernetes allows you to pass command-line arguments to containers, which can be facilitated to provide configuration to the applications:&lt;/p&gt; &lt;pre&gt;apiVersion: apps/v1 kind: Deployment metadata: name: game-server-deployment spec: ... template: spec: containers: - name: server args: - "gravity=10" - "colorMode=dark" &lt;/pre&gt; &lt;p&gt;The command-line arguments &lt;code&gt;gravity&lt;/code&gt; and &lt;code&gt;colorMode&lt;/code&gt; will be passed to the application running in the container. The application program needs to read the command-line arguments and apply them.&lt;/p&gt; &lt;p&gt;This Kubernetes configuration pattern is not very flexible: Configuration is hardcoded in the YAML, so the configuration is coupled to the &lt;code&gt;Deployment&lt;/code&gt;. Also, this pattern doesn’t scale well when the same configuration is needed in multiple &lt;code&gt;Deployment&lt;/code&gt;s.&lt;/p&gt; &lt;p&gt;This practice can be used for migrating legacy software that uses command-line arguments for configuration into containers. However, any of the alternatives presented in this article would be better in terms of flexibility and scalability.&lt;/p&gt; &lt;h2&gt;Configuration with environment variables&lt;a name="basics_2"&gt;&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;Kubernetes allows you to set environment variables in containers. Applications in containers may use these environment variables as configuration options. For example:&lt;/p&gt; &lt;pre&gt;apiVersion: apps/v1 kind: Deployment metadata: name: game-server-deployment spec: template: spec: containers: - name: server env: - name: GRAVITY value: "10" - name: COLOR_MODE value: "dark" &lt;/pre&gt; &lt;p&gt;The environment variables &lt;code&gt;GRAVITY&lt;/code&gt; and &lt;code&gt;COLOR_MODE&lt;/code&gt; will be passed to the application running in the container. The application program needs to read the environment variables and apply them. The &lt;code&gt;Deployment&lt;/code&gt; will be rolled out when there is a change in the environment variables.&lt;/p&gt; &lt;p&gt;This pattern is almost identical to the previous one, &lt;a href="#basics_1"&gt;Configuration with command-line arguments&lt;/a&gt;, as the configuration is still hardcoded in the &lt;code&gt;Deployment&lt;/code&gt; YAML. However, environment variables are easier and cleaner to define and provide to containers than command-line arguments. Also, in the command-line arguments approach, the configuration and the command to run the application are in the same place.&lt;/p&gt; &lt;p&gt;As you will see soon, Kubernetes also lets you pass environment variables to get values from different sources, such as &lt;code&gt;Secret&lt;/code&gt;s, &lt;code&gt;ConfigMap&lt;/code&gt;s, and references.&lt;/p&gt; &lt;p&gt;If you don&amp;#8217;t need to share the configuration among different &lt;code&gt;Deployment&lt;/code&gt;s or containers, this pattern provides the simplest and most straightforward configuration method.&lt;/p&gt; &lt;h2&gt;Antipattern: Configuration with NFS volume mounts&lt;a name="basics_3"&gt;&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;It is possible to mount network drives to containers with Kubernetes.&lt;/p&gt; &lt;p&gt;In this pattern, the idea is to mount a volume with a configuration file in it to a container. Later, the application running in the container can read the configuration file from the file system.&lt;/p&gt; &lt;p&gt;To create such volume, we can use a network file system (NFS) volume, as shown in Figure 1.&lt;/p&gt; &lt;div id="attachment_825217" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/basics_3.png"&gt;&lt;img aria-describedby="caption-attachment-825217" class="wp-image-825217" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/basics_3.png" alt="This Kubernetes configuration pattern performs configuration with an NFS volume mount." width="640" height="431" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/basics_3.png 786w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/basics_3-300x202.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/basics_3-768x517.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-825217" class="wp-caption-text"&gt;Figure 1: You can mount a volume with a configuration into a container.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Here is the part of the &lt;code&gt;Deployment&lt;/code&gt; for implementing the mount:&lt;/p&gt; &lt;pre&gt;apiVersion: apps/v1 kind: Deployment metadata: name: game-server-deployment spec: ... template: spec: volumes: - name: nfs-volume nfs: server: nfs.example.com path: /configs/game-server/ containers: - name: server volumeMounts: - name: nfs-volume mountPath: /etc/config &lt;/pre&gt; &lt;p&gt;In this example, the &lt;code&gt;game-server&lt;/code&gt; container will be able to read the files under the &lt;code&gt;/etc/config/&lt;/code&gt; directory, and that directory will be a reflection of the &lt;code&gt;/configs/game-server/&lt;/code&gt; path in the NFS server that is defined in the &lt;code&gt;Deployment&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;You need to create the configuration files manually on the NFS server before creating the &lt;code&gt;Deployment&lt;/code&gt; on Kubernetes.&lt;/p&gt; &lt;p&gt;This pattern is very similar to the &lt;a href="#basics_5"&gt;Configuration with a ConfigMap mounted as a file&lt;/a&gt; pattern, which I will show shortly. The difference here is that you need to use NFS and create the configuration file manually on the NFS server. Because of these requirements, this solution is an antipattern, although in some cases it is useful. One of the cases is when the configuration is very large, such as &lt;a target="_blank" rel="nofollow" href="/topics/ai-ml"&gt;machine learning&lt;/a&gt; models (if they can be considered part of configuration). Another useful case is when the configuration must be immutable.&lt;/p&gt; &lt;h2&gt;Antipattern: Configuration with init containers&lt;a name="basics_4"&gt;&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;Kubernetes has a concept of &lt;i&gt;init containers&lt;/i&gt;. These containers run before the main containers and configure the environment for them. You can exploit this feature to handle an application&amp;#8217;s configuration.&lt;/p&gt; &lt;p&gt;In this pattern, the configuration lives in a separate image that is run by an init container. That container copies the configuration it holds into a volume shared with other containers, as illustrated by Figure 2. The init container holds the configuration and later copies the configuration over to the volume that is shared with the server container.&lt;/p&gt; &lt;div id="attachment_825227" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/basics_4.png"&gt;&lt;img aria-describedby="caption-attachment-825227" class="wp-image-825227" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/basics_4.png" alt="In this Kubernetes configuration pattern, an init container copies a configuration to the main container through a shared volume mounted in the main container." width="640" height="461" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/basics_4.png 899w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/basics_4-300x216.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/basics_4-768x553.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-825227" class="wp-caption-text"&gt;Figure 2: An init container can copy a configuration to the main container.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Here is the part of the &lt;code&gt;Deployment&lt;/code&gt; for implementing the init container:&lt;/p&gt; &lt;pre&gt;apiVersion: apps/v1 kind: Deployment metadata: name: game-server-deployment spec: ... template: spec: volumes: - name: config-directory emptyDir: {} initContainers: - name: init image: my.image-repository.com/initcontainer volumeMounts: - name: config-directory mountPath: /etc/config containers: - name: server image: my.image-repository.com/maincontainer volumeMounts: - name: config-directory mountPath: /etc/config &lt;/pre&gt; &lt;p&gt;You need to build the init container that way, though. For example:&lt;/p&gt; &lt;pre&gt;FROM busybox ADD configuration.properties /config-src/configuration.properties ENTRYPOINT [ "sh", "-c", "cp /config-src/* /etc/config", "--" ] &lt;/pre&gt; &lt;p&gt;The &lt;code&gt;config.properties&lt;/code&gt; file is the configuration file that is added to the container image during its build. Later, the file is simply copied with the &lt;code&gt;cp&lt;/code&gt; command. So, the configuration should be available during the init container&amp;#8217;s build time.&lt;/p&gt; &lt;p&gt;Any changes done to the configuration file by the server container in the shared volume will be transient. Also, having the configuration available during the build time is not very flexible and not &lt;a target="_blank" rel="nofollow" href="https://12factor.net/config"&gt;12-factor-ish&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;You can use this pattern in situations similar to those for the &lt;a href="#basics_3"&gt;Configuration with NFS volume mounts&lt;/a&gt; pattern, when the configuration file is too large or if an immutable configuration is targeted. But using an init container as shown here is considered an antipattern, except for these specific cases.&lt;/p&gt; &lt;h2&gt;Configuration with a ConfigMap mounted as a file&lt;a name="basics_5"&gt;&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;It is possible to mount a Kubernetes &lt;code&gt;ConfigMap&lt;/code&gt; into a container as a file, as shown in Figure 3.&lt;/p&gt; &lt;div id="attachment_825237" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/basics_5.png"&gt;&lt;img aria-describedby="caption-attachment-825237" class="wp-image-825237" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/basics_5.png" alt="In this Kubernetes configuration pattern, a ConfigMap is mounted as a file in a volume." width="640" height="324" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/basics_5.png 782w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/basics_5-300x152.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/basics_5-768x389.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-825237" class="wp-caption-text"&gt;Figure 3: A ConfigMap is mounted as a file in a volume.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Here is the part of the &lt;code&gt;Deployment&lt;/code&gt; for mounting the &lt;code&gt;ConfigMap&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;apiVersion: v1 kind: ConfigMap metadata: name: game-config data: game.properties: | gravity=10 colorMode=dark --- apiVersion: apps/v1 kind: Deployment metadata: name: game-server-deployment spec: ... template: spec: containers: - name: server volumeMounts: - mountPath: /etc/config name: game-config-volume volumes: - name: game-config-volume configMap: name: game-config &lt;/pre&gt; &lt;p&gt;The data inside the &lt;code&gt;ConfigMap&lt;/code&gt; will be mounted to the &lt;code&gt;Deployment&lt;/code&gt; as a file in a volume. The key in the data field, &lt;code&gt;game.properties&lt;/code&gt;, is used as the file name, and the value of that key will be the file content. The configuration file path will be &lt;code&gt;/etc/config/game.properties&lt;/code&gt;. When you follow this procedure, the game application can read and process the &lt;code&gt;.properties&lt;/code&gt; file.&lt;/p&gt; &lt;p&gt;This configuration pattern is easy to understand and manage. The configuration can be read as a whole file in the application container, which might be simpler and faster. Also, the same &lt;code&gt;ConfigMap&lt;/code&gt; can be mounted to different containers easily, compared to setting values from &lt;code&gt;ConfigMap&lt;/code&gt;s as &lt;a href="#basics_2"&gt;environment variables&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;With this pattern, the configuration is loosely coupled from the application. The configuration can be changed without touching the &lt;code&gt;Deployment&lt;/code&gt;. It is possible to use the same configuration in multiple applications as well as to mount multiple &lt;code&gt;ConfigMap&lt;/code&gt;s into a single &lt;code&gt;Deployment&lt;/code&gt;. Multiple &lt;code&gt;ConfigMap&lt;/code&gt;s provide more granularity when needed.&lt;/p&gt; &lt;p&gt;However, this pattern needs a file read operation within the application running in the container, which might not be ideal in every case. Furthermore, when using this pattern, the configuration that the &lt;code&gt;Deployment&lt;/code&gt; is using is not visible directly on the &lt;code&gt;Deployment&lt;/code&gt; or the &lt;code&gt;Pod&lt;/code&gt;s created for the &lt;code&gt;Deployment&lt;/code&gt;. A human operator needs to check the &lt;code&gt;ConfigMap&lt;/code&gt; to see the configuration values.&lt;/p&gt; &lt;p&gt;When there are a lot of configuration options, a &lt;code&gt;ConfigMap&lt;/code&gt; mount makes sense because the configuration is available as a whole with a single &lt;code&gt;volumeMount&lt;/code&gt;. Also, when a specific file format is used, such as the &lt;code&gt;.properties&lt;/code&gt; file in the previous example, the file content can be fed to a properties file parser, which is available in many languages.&lt;/p&gt; &lt;p&gt;By default, the &lt;code&gt;Deployment&lt;/code&gt; will not be restarted when there is a change in the mounted &lt;code&gt;ConfigMap&lt;/code&gt;. There are techniques to restart the &lt;code&gt;Deployment&lt;/code&gt;, but they are outside the scope of this article.&lt;/p&gt; &lt;p&gt;When there are not many configuration options, you can use alternative patterns like &lt;a href="#basics_7"&gt;Setting environment variables from ConfigMaps&lt;/a&gt; (shown below) to avoid the file read operation and the volume mount.&lt;/p&gt; &lt;p&gt;You can make a mounted &lt;code&gt;ConfigMap&lt;/code&gt; read only, but not immutable. Cluster administrators will be able to change the &lt;code&gt;ConfigMap&lt;/code&gt;, and thus the configuration for an application. If immutability is needed, use the &lt;a href="#basics_3"&gt;Configuration with NFS volume mounts&lt;/a&gt; or &lt;a href="#basics_4"&gt;Configuration with init containers&lt;/a&gt; pattern.&lt;/p&gt; &lt;h2&gt;Configuration with ConfigMaps mounted as multiple files&lt;a name="basics_6"&gt;&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;When a &lt;code&gt;ConfigMap&lt;/code&gt; contains multiple keys, it is possible to mount these keys as separate files.&lt;/p&gt; &lt;p&gt;This pattern is the same as the &lt;a href="#basics_5"&gt;Configuration with a ConfigMap mounted as a file&lt;/a&gt; pattern, except that it uses multiple files to separate parts of the configuration, thus creating different scopes. Figure 4 shows this pattern.&lt;/p&gt; &lt;div id="attachment_825247" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/basics_6.png"&gt;&lt;img aria-describedby="caption-attachment-825247" class="wp-image-825247" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/basics_6.png" alt="This Kubernetes configuration pattern mounts different ConfigMaps as multiple files in a volume." width="640" height="324" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/basics_6.png 841w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/basics_6-300x152.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/basics_6-768x389.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-825247" class="wp-caption-text"&gt;Figure 4: ConfigMaps are mounted as multiple files in a volume.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Here is the part of the &lt;code&gt;Deployment&lt;/code&gt; for creating the &lt;code&gt;ConfigMap&lt;/code&gt;s and volume:&lt;/p&gt; &lt;pre&gt;apiVersion: v1 kind: ConfigMap metadata: name: game-config data: game.properties: | gravity=10 ui.properties: | colorMode=dark --- apiVersion: apps/v1 kind: Deployment metadata: name: game-server-deployment spec: ... template: spec: containers: - name: server volumeMounts: - mountPath: /etc/config name: game-config-volume volumes: - name: game-config-volume configMap: name: game-config &lt;/pre&gt; &lt;p&gt;As in the &lt;a href="#basics_5"&gt;Configuration with a ConfigMap mounted as a file&lt;/a&gt; pattern, the data inside the &lt;code&gt;ConfigMap&lt;/code&gt; will be mounted to the &lt;code&gt;Deployment&lt;/code&gt; as files in a volume. This time, though, there will be two files: &lt;code&gt;/etc/config/game.properties&lt;/code&gt; and &lt;code&gt;/etc/config/ui.properties&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;This separation is useful in some cases, such as when application modules read their configurations independently, or when the configuration has so many options that it makes sense to split the options into multiple logical parts while keeping everything in a single &lt;code&gt;ConfigMap&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;Configuration with ConfigMaps used as a source for environment variables&lt;a name="basics_7"&gt;&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;This pattern is preferred when there are not many configuration options and when I/O operations are undesired. Figure 5 shows the pattern.&lt;/p&gt; &lt;div id="attachment_825257" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/basics_7.png"&gt;&lt;img aria-describedby="caption-attachment-825257" class="wp-image-825257" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/basics_7.png" alt="This Kubernetes configuration pattern uses a ConfigMap as a source for environment variables." width="640" height="324" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/basics_7.png 822w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/basics_7-300x152.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/basics_7-768x389.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-825257" class="wp-caption-text"&gt;Figure 5: A ConfigMap serves as a source for environment variables.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Here is the part of the &lt;code&gt;Deployment&lt;/code&gt; for implementing the &lt;code&gt;ConfigMap&lt;/code&gt; and environment variables:&lt;/p&gt; &lt;pre&gt;apiVersion: v1 kind: ConfigMap metadata: name: game-config data: gravity: "10" colorMode: "dark" --- apiVersion: apps/v1 kind: Deployment metadata: name: game-server-deployment spec: ... template: spec: containers: - name: server env: - name: GRAVITY valueFrom: configMapKeyRef: name: game-config key: gravity - name: COLOR_MODE valueFrom: configMapKeyRef: name: game-config key: colorMode &lt;/pre&gt; &lt;p&gt;The environment variables will be set with the values from &lt;code&gt;ConfigMap&lt;/code&gt;, ending up as &lt;code&gt;GRAVITY=10&lt;/code&gt; and &lt;code&gt;COLOR_MODE=dark&lt;/code&gt;. The application running in the container needs to read the environment variables and use them as the configuration.&lt;/p&gt; &lt;p&gt;This pattern provides a nice way to bind the options in the &lt;code&gt;ConfigMap&lt;/code&gt; to the configuration options that are actually used in the application. There might be more options in the &lt;code&gt;ConfigMap&lt;/code&gt;, but not every application needs all of the options.&lt;/p&gt; &lt;p&gt;The mappings from &lt;code&gt;ConfigMap&lt;/code&gt; keys to environment variables are explicit and make these bindings human readable. Furthermore, the application does not need any file I/O operations.&lt;/p&gt; &lt;p&gt;However, if there are too many configuration options that need to be bound from a &lt;code&gt;ConfigMap&lt;/code&gt; to environment variables, things can get messy. In that case, the &lt;a href="#basics_5"&gt;Configuration with a ConfigMap mounted as a file&lt;/a&gt; pattern is preferred.&lt;/p&gt; &lt;h2&gt;Configuration with Secrets&lt;a name="basics_8"&gt;&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;Anything done for configuration can theoretically be done with &lt;code&gt;Secret&lt;/code&gt;s. It is better to store credentials, certificates, and similar things in a &lt;code&gt;Secret&lt;/code&gt; than in a &lt;code&gt;ConfigMap&lt;/code&gt;, because &lt;code&gt;Secret&lt;/code&gt;s are more secure.&lt;/p&gt; &lt;p&gt;For example, to mount a &lt;code&gt;Secret&lt;/code&gt; as a file on a volume, you can use the following YAML:&lt;/p&gt; &lt;pre&gt;apiVersion: v1 kind: Secret type: Opaque metadata: name: game-secret data: databaseUsername: Zm9v databasePassword: YmFy --- apiVersion: apps/v1 kind: Deployment metadata: name: game-server-deployment spec: ... template: spec: containers: - name: server volumeMounts: - mountPath: /etc/config name: game-secret-volume volumes: - name: game-secret-volume configMap: name: game-secret &lt;/pre&gt; &lt;p&gt;This will create two files that are available to the server container: &lt;code&gt;/etc/config/databaseUsername&lt;/code&gt; and &lt;code&gt;/etc/config/databasePassword&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;As shown in this example, simply replacing the &lt;code&gt;ConfigMap&lt;/code&gt; with &lt;code&gt;Secret&lt;/code&gt; should work most of the time.&lt;/p&gt; &lt;h2&gt;Conclusion to Part 1&lt;/h2&gt; &lt;p&gt;The Kubernetes configuration patterns described in this article use Kubernetes primitives and will help you configure your application running on Kubernetes. They are relatively simple to implement. The second part of this article introduces patterns specific to Kubernetes controllers. These will require coding against the Kubernetes API.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F28%2Fkubernetes-configuration-patterns-part-1-patterns-for-kubernetes-primitives%2F&amp;#38;linkname=Kubernetes%20configuration%20patterns%2C%20Part%201%3A%20Patterns%20for%20Kubernetes%20primitives" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F28%2Fkubernetes-configuration-patterns-part-1-patterns-for-kubernetes-primitives%2F&amp;#38;linkname=Kubernetes%20configuration%20patterns%2C%20Part%201%3A%20Patterns%20for%20Kubernetes%20primitives" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F28%2Fkubernetes-configuration-patterns-part-1-patterns-for-kubernetes-primitives%2F&amp;#38;linkname=Kubernetes%20configuration%20patterns%2C%20Part%201%3A%20Patterns%20for%20Kubernetes%20primitives" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F28%2Fkubernetes-configuration-patterns-part-1-patterns-for-kubernetes-primitives%2F&amp;#38;linkname=Kubernetes%20configuration%20patterns%2C%20Part%201%3A%20Patterns%20for%20Kubernetes%20primitives" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F28%2Fkubernetes-configuration-patterns-part-1-patterns-for-kubernetes-primitives%2F&amp;#38;linkname=Kubernetes%20configuration%20patterns%2C%20Part%201%3A%20Patterns%20for%20Kubernetes%20primitives" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F28%2Fkubernetes-configuration-patterns-part-1-patterns-for-kubernetes-primitives%2F&amp;#38;linkname=Kubernetes%20configuration%20patterns%2C%20Part%201%3A%20Patterns%20for%20Kubernetes%20primitives" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F28%2Fkubernetes-configuration-patterns-part-1-patterns-for-kubernetes-primitives%2F&amp;#38;linkname=Kubernetes%20configuration%20patterns%2C%20Part%201%3A%20Patterns%20for%20Kubernetes%20primitives" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F28%2Fkubernetes-configuration-patterns-part-1-patterns-for-kubernetes-primitives%2F&amp;#038;title=Kubernetes%20configuration%20patterns%2C%20Part%201%3A%20Patterns%20for%20Kubernetes%20primitives" data-a2a-url="https://developers.redhat.com/blog/2021/04/28/kubernetes-configuration-patterns-part-1-patterns-for-kubernetes-primitives/" data-a2a-title="Kubernetes configuration patterns, Part 1: Patterns for Kubernetes primitives"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/04/28/kubernetes-configuration-patterns-part-1-patterns-for-kubernetes-primitives/"&gt;Kubernetes configuration patterns, Part 1: Patterns for Kubernetes primitives&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/b0j_RiD9TMo" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;This article is the first in a two-part article series on Kubernetes configuration patterns, which represent ways of configuring Kubernetes applications and controllers. Part 1 introduces simple approaches that use only Kubernetes primitives. These patterns are applicable to any application running on Kubernetes. Part 2 will introduce more advanced patterns. These patterns require you to [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/04/28/kubernetes-configuration-patterns-part-1-patterns-for-kubernetes-primitives/"&gt;Kubernetes configuration patterns, Part 1: Patterns for Kubernetes primitives&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/04/28/kubernetes-configuration-patterns-part-1-patterns-for-kubernetes-primitives/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">824267</post-id><dc:creator>Ali Ok</dc:creator><dc:date>2021-04-28T07:00:45Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/04/28/kubernetes-configuration-patterns-part-1-patterns-for-kubernetes-primitives/</feedburner:origLink></entry><entry><title>Value range propagation in GCC with Project Ranger</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/7KJZvHHtcos/" /><category term="C" /><category term="Linux" /><category term="Performance" /><category term="Programming Languages" /><category term="gcc" /><category term="Project Ranger" /><category term="value range propagation" /><author><name>Andrew MacLeod</name></author><id>https://developers.redhat.com/blog/?p=863407</id><updated>2021-04-28T07:00:26Z</updated><published>2021-04-28T07:00:26Z</published><content type="html">&lt;p&gt;One of the optimizations &lt;a target="_blank" rel="nofollow" href="https://gcc.gnu.org/"&gt;GNU Compiler Collection (GCC)&lt;/a&gt; performs on &lt;a target="_blank" rel="nofollow" href="/topics/c"&gt;C and C++ programs&lt;/a&gt; is value range propagation (VRP). VRP determines what subranges a variable can contain and uses that information to eliminate redundant calculations. This in turn makes programs smaller and run faster.&lt;/p&gt; &lt;p&gt;As a simple example, consider the two nested &lt;code&gt;if&lt;/code&gt; statements in the following C snippet:&lt;/p&gt; &lt;pre&gt;if (a &amp;#60; 100 &amp;#38;&amp;#38; b &amp;#60; 100) { c = a + b; if (c &amp;#60; 200) foo (c); }&lt;/pre&gt; &lt;p&gt;We know that, if the outer &lt;code&gt;if&lt;/code&gt; statement runs its block, &lt;code&gt;a&lt;/code&gt; + &lt;code&gt;b&lt;/code&gt; cannot be larger than 99 + 99, or 198. This means we don’t need to check &lt;code&gt;if (c &amp;#60; 200)&lt;/code&gt; and can rewrite the snippet to be simply:&lt;/p&gt; &lt;pre&gt;if (a &amp;#60; 100 &amp;#38;&amp;#38; b &amp;#60; 100) foo (a + b);&lt;/pre&gt; &lt;p&gt;Branches are expensive in programs, so this sort of thing is a big deal. It&amp;#8217;s an even bigger deal in the modern world where we are concerned about security issues like buffer overflows (accessing data outside of expected bounds). The compiler may add range checks or do other verification to harden the code, but this comes at a cost. VRP can determine that some of those checks are not needed. This produces a faster program that is still safe. We can also use range information to identify dangerous segments of code and alert the user with a warning. The list of potential uses for VRP regularly grows.&lt;/p&gt; &lt;p&gt;The initial version of VRP in GCC was created in 2006 when static single assignment (SSA) was a new infrastructure in the compiler. With a renewed interest in utilizing range information, GCC’s original version of VRP simply isn&amp;#8217;t flexible enough. Numerous improvements have been made over the past decade, but there is still a long list of outstanding change requests. The underlying infrastructure simply has too many shortcomings to address current needs. The oldest request originates in 2007!&lt;/p&gt; &lt;h2&gt;Enter Project Ranger&lt;/h2&gt; &lt;p&gt;We’ve been working on Project Ranger for more than three years now. It is designed from the ground up to resolve all the outstanding issues and replace the current VRP pass. Other passes in the compiler will also be able to access this range information. This upgrade is not without difficulties, as anyone who has tried to revamp a 30-year-old codebase may have experienced. An &lt;a target="_blank" rel="nofollow" href="/blog/2019/10/11/a-upside-down-approach-to-gcc-optimizations/"&gt;earlier article&lt;/a&gt; covers some of the new technology in this project.&lt;/p&gt; &lt;p&gt;GCC 10 (the current release) contains an object-oriented replacement for the underlying range calculations we call &lt;em&gt;range-ops&lt;/em&gt;. Range-ops is responsible for solving various kinds of range equations based on each statement. It is also pre-wired to support a new representation of ranges. Range-ops was the first stage of Ranger to make it into GCC. This stage has been live for almost a year and continues to perform well.&lt;/p&gt; &lt;p&gt;The upcoming GCC 11 release will contain:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;A new implementation of ranges that allows more precise representation.&lt;/li&gt; &lt;li&gt;A new Ranger VRP infrastructure that can make use of these precise ranges.&lt;/li&gt; &lt;li&gt;A hybrid VRP pass for this release only, which contains both the original and the new version of VRP.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;A couple of other passes are also utilizing Project Ranger to provide some combination of improved speed and better results.&lt;/p&gt; &lt;h2&gt;Why is there a hybrid pass?&lt;/h2&gt; &lt;p&gt;Development of Project Ranger will continue into GCC 12, where we expect to see the project fully realized. Without the full suite of features, we cannot fully replace the original VRP pass.&lt;/p&gt; &lt;p&gt;The hybrid pass queries both the original and the new VRP engines and combines the results. This hybrid pass helps us optimize everything we used to do, as well as getting some new opportunities. It also allows us to easily track differences between the old and new approaches. Not to worry—the hybrid pass is still quite fast.&lt;/p&gt; &lt;p&gt;The primary missing component is &lt;em&gt;relation processing&lt;/em&gt;. The initial example in this article showed how ranges can be used to remove conditions. There are times when a relationship between operands must be known in order to remove the condition. An example follows:&lt;/p&gt; &lt;pre&gt;if (a == b) if (b == c) if (a &amp;#60; c) // This can never be true call (b)&lt;/pre&gt; &lt;p&gt;The final &lt;code&gt;if&lt;/code&gt; condition is always false, but we can&amp;#8217;t determine that based on ranges alone. There might be no discernible ranges for any of these variables. To detect the value of the expression, we need to introduce a thorough knowledge of relations. If we know that &lt;code&gt;a&lt;/code&gt; == &lt;code&gt;b&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; == &lt;code&gt;c&lt;/code&gt;, we can also conclude that &lt;code&gt;a&lt;/code&gt; == &lt;code&gt;c&lt;/code&gt;, and therefore &lt;code&gt;a &amp;#60; c&lt;/code&gt; can never be true. It seems easy and obvious, but it is not quite so natural in the compiler.&lt;/p&gt; &lt;p&gt;The original version of VRP has numerous ad-hoc additions that allow it to perform this optimization sometimes. This is why GCC 11 has a hybrid pass. These important optimizations can still be performed while benefiting from the other features Ranger provides. We also get a full release cycle to compare the new version to the old one and ensure we miss nothing.&lt;/p&gt; &lt;p&gt;This new relation processing code is ready for the start of the GCC 12 development cycle. We are leveraging the new range-ops infrastructure to also evaluate relationships. This enhancement will allow any kind of statement that may calculate a range to also provide relationships between operands:&lt;/p&gt; &lt;pre&gt;a = b + 2    // Establishes a &amp;#62; b if (a &amp;#60; b)   // We can fold this away since it can never be true&lt;/pre&gt; &lt;p&gt;We can conclude that &lt;code&gt;a &amp;#62; b&lt;/code&gt; after the addition, and eliminate the &lt;code&gt;if&lt;/code&gt; statement. We expect to expose and exploit a lot more of these implied relationships in GCC 12.&lt;/p&gt; &lt;h2&gt;Into the future&lt;/h2&gt; &lt;p&gt;Project Ranger should be the only VRP implementation required in GCC 12. We can remove the legacy code and the various compatibility layers it required. This will improve compilation speed as well as reduce maintenance effort. Finally, we expect there will be additional passes making use of the more precise ranges that are easily available.&lt;/p&gt; &lt;p&gt;Building on this into the future, we also have plans for:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Handling ranges for types other than integral values (floats, complex numbers, etc.).&lt;/li&gt; &lt;li&gt;Bit value tracking (known 0 and 1 bits).&lt;/li&gt; &lt;li&gt;Additional passes making use of this infrastructure.&lt;/li&gt; &lt;li&gt;Continued improvement in memory usage and compilation speed.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;You may not be able to tell when you compile a program, but there certainly is a lot of new work going on under the covers. GCC 11 has some range improvements, but we hope to resolve most, if not all, of the 26 outstanding deficiencies and feature requests when GCC 12 comes out.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F28%2Fvalue-range-propagation-in-gcc-with-project-ranger%2F&amp;#38;linkname=Value%20range%20propagation%20in%20GCC%20with%20Project%20Ranger" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F28%2Fvalue-range-propagation-in-gcc-with-project-ranger%2F&amp;#38;linkname=Value%20range%20propagation%20in%20GCC%20with%20Project%20Ranger" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F28%2Fvalue-range-propagation-in-gcc-with-project-ranger%2F&amp;#38;linkname=Value%20range%20propagation%20in%20GCC%20with%20Project%20Ranger" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F28%2Fvalue-range-propagation-in-gcc-with-project-ranger%2F&amp;#38;linkname=Value%20range%20propagation%20in%20GCC%20with%20Project%20Ranger" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F28%2Fvalue-range-propagation-in-gcc-with-project-ranger%2F&amp;#38;linkname=Value%20range%20propagation%20in%20GCC%20with%20Project%20Ranger" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F28%2Fvalue-range-propagation-in-gcc-with-project-ranger%2F&amp;#38;linkname=Value%20range%20propagation%20in%20GCC%20with%20Project%20Ranger" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F28%2Fvalue-range-propagation-in-gcc-with-project-ranger%2F&amp;#38;linkname=Value%20range%20propagation%20in%20GCC%20with%20Project%20Ranger" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F28%2Fvalue-range-propagation-in-gcc-with-project-ranger%2F&amp;#038;title=Value%20range%20propagation%20in%20GCC%20with%20Project%20Ranger" data-a2a-url="https://developers.redhat.com/blog/2021/04/28/value-range-propagation-in-gcc-with-project-ranger/" data-a2a-title="Value range propagation in GCC with Project Ranger"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/04/28/value-range-propagation-in-gcc-with-project-ranger/"&gt;Value range propagation in GCC with Project Ranger&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/7KJZvHHtcos" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;One of the optimizations GNU Compiler Collection (GCC) performs on C and C++ programs is value range propagation (VRP). VRP determines what subranges a variable can contain and uses that information to eliminate redundant calculations. This in turn makes programs smaller and run faster. As a simple example, consider the two nested if statements in [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/04/28/value-range-propagation-in-gcc-with-project-ranger/"&gt;Value range propagation in GCC with Project Ranger&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/04/28/value-range-propagation-in-gcc-with-project-ranger/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">863407</post-id><dc:creator>Andrew MacLeod</dc:creator><dc:date>2021-04-28T07:00:26Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/04/28/value-range-propagation-in-gcc-with-project-ranger/</feedburner:origLink></entry><entry><title type="html">Quarkus 1.13.3.Final released - Maintenance release</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/ZN9O730gtZM/" /><author><name /></author><id>https://quarkus.io/blog/quarkus-1-13-3-final-released/</id><updated>2021-04-28T00:00:00Z</updated><content type="html">We just released 1.13.3.Final, a new maintenance release for the 1.13 release train. 1.13.3.Final is a safe upgrade for everyone using Quarkus 1.13. If you are not using 1.13 already, please refer to the 1.13 migration guide. What’s new? Full changelog You can get the full changelog of 1.13.3.Final on...&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/ZN9O730gtZM" height="1" width="1" alt=""/&gt;</content><dc:creator /><feedburner:origLink>https://quarkus.io/blog/quarkus-1-13-3-final-released/</feedburner:origLink></entry><entry><title>4 reasons you’ll love using Red Hat OpenShift Data Science</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/tu6B77v5I90/" /><category term="Containers" /><category term="Kubernetes" /><category term="Machine Learning" /><category term="Python" /><category term="JupyterHub" /><category term="OpenShift Data Hub" /><category term="OpenShift Data Science" /><author><name>Anish Asthana</name></author><id>https://developers.redhat.com/blog/?p=904257</id><updated>2021-04-27T13:00:47Z</updated><published>2021-04-27T13:00:47Z</published><content type="html">&lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/technologies/cloud-computing/openshift/openshift-data-science"&gt;Red Hat OpenShift Data Science&lt;/a&gt; is a managed cloud service built from a curated set of components from the upstream &lt;a target="_blank" rel="nofollow" href="https://opendatahub.io/"&gt;Open Data Hub&lt;/a&gt; project. It aims to provide a stable sandbox in which data scientists can develop, train, and test their machine learning (ML) workloads and then deploy results in a container-ready format. This article summarizes the advantages of using OpenShift Data Science in your &lt;a target="_blank" rel="nofollow" href="/topics/ai-ml"&gt;machine learning&lt;/a&gt; projects.&lt;/p&gt; &lt;h2&gt;Containers make data science easy&lt;/h2&gt; &lt;p&gt;While tools like JupyterLab (shown in Figure 1) already offer intuitive ways for data scientists to develop models on their machines, there are always inherent complexities involved with collaboration and sharing work. Moreover, using specialized hardware such as powerful GPUs can be very expensive when you have to buy and maintain your own. The JupyterHub that is included with OpenShift Data Science lets data scientists take their development environments to the cloud. Because all of the workloads are run as containers, collaboration is as easy as sharing an image with your team members, or even simply &lt;a target="_blank" rel="nofollow" href="https://www.youtube.com/watch?v=p8WGxiH55lE"&gt;adding it to the list of default containers&lt;/a&gt; they can use. GPUs and large amounts of memory suddenly become a lot more accessible, too, since you are no longer limited by what your laptop can support. All this, and you get to keep the same UX and development workflow you&amp;#8217;ve always loved, too.&lt;/p&gt; &lt;div id="attachment_904947" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/04/jupyterlab-notebook.png"&gt;&lt;img aria-describedby="caption-attachment-904947" class="wp-image-904947 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/04/jupyterlab-notebook-1024x540.png" alt="An open JupyterLab notebook." width="640" height="338" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/04/jupyterlab-notebook-1024x540.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/jupyterlab-notebook-300x158.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/jupyterlab-notebook-768x405.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-904947" class="wp-caption-text"&gt;Figure 1: A JupyterLab notebook.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Securely built notebook images&lt;/h2&gt; &lt;p&gt;Software stacks, especially those involved in machine learning, tend to be complex beasts. There are numerous modules and libraries in the &lt;a target="_blank" rel="nofollow" href="/blog/category/python/"&gt;Python&lt;/a&gt; ecosystem that can be used, so determining which versions of what libraries to use can be very challenging. As Figure 2 shows, OpenShift Data Science comes with many packaged notebook images that have been built with insight from data scientists and recommendation engines such as &lt;a target="_blank" rel="nofollow" href="/blog/2020/09/30/ai-software-stack-inspection-with-thoth-and-tensorflow/"&gt;Thoth adviser&lt;/a&gt;. This allows data scientists to start new projects quickly on the right foot without worrying about downloading unproven and possibly insecure images from random upstream repositories.&lt;/p&gt; &lt;div id="attachment_904907" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/04/notebook-selection.png"&gt;&lt;img aria-describedby="caption-attachment-904907" class="wp-image-904907" src="https://developers.redhat.com/blog/wp-content/uploads/2021/04/notebook-selection.png" alt="The dialog to create and start a notebook server in JupyterHub." width="640" height="354" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/04/notebook-selection.png 1019w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/notebook-selection-300x166.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/notebook-selection-768x424.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-904907" class="wp-caption-text"&gt;Figure 2: Notebook images available in JupyterHub.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Integrations with third-party machine learning tools&lt;/h2&gt; &lt;p&gt;We have all run into situations where our favorite tools or services don&amp;#8217;t play well with one another. OpenShift Data Science is designed with flexibility in mind. As Figure 3 shows, a wide range of open source and third-party &lt;a target="_blank" rel="nofollow" href="/topics/ai-ml"&gt;AI/ML&lt;/a&gt; tools can be used with OpenShift Data Science. These tools support the complete machine learning lifecycle, from data engineering and feature extraction to model deployment and management. No more leaving your favorite toys behind.&lt;/p&gt; &lt;div id="attachment_905017" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/04/ISV-Ecosystem-1.png"&gt;&lt;img aria-describedby="caption-attachment-905017" class="wp-image-905017 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/04/ISV-Ecosystem-1-1024x489.png" alt="Explore third-party AI/ML tools available for use with OpenShift Data Science." width="640" height="306" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/04/ISV-Ecosystem-1-1024x489.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/ISV-Ecosystem-1-300x143.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/ISV-Ecosystem-1-768x367.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-905017" class="wp-caption-text"&gt;Figure 3: Third-party integrations available to use with OpenShift Data Science.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Tried and tested with Operate First&lt;/h2&gt; &lt;p&gt;The Open Data Hub is an &lt;a target="_blank" rel="nofollow" href="/topics/open-source"&gt;open source&lt;/a&gt; community project consisting of over 30 AI/ML tools that cover the entire lifecycle of possible needs for any machine learning initiative. The &lt;a target="_blank" rel="nofollow" href="https://www.operate-first.cloud/"&gt;Operate First&lt;/a&gt; initiative aims to deploy a subset of the most-used components in an open environment to gain additional operational expertise and to help harden the upstream project. OpenShift Data Science takes a core set of the most commonly used &lt;i&gt;and&lt;/i&gt; stable components and delivers them as a managed cloud service on &lt;a target="_blank" rel="nofollow" href="https://www.openshift.com/products/dedicated/"&gt;Red Hat OpenShift Dedicated&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://www.openshift.com/products/amazon-openshift"&gt;Red Hat OpenShift Service on AWS&lt;/a&gt;. This means that data scientists can focus on rapid iteration and experimentation while leveraging Red Hat&amp;#8217;s experience in running complex workloads on &lt;a target="_blank" rel="nofollow" href="/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="http://www.redhat.com/en/technologies/cloud-computing/openshift/openshift-data-science"&gt;Find out more about OpenShift Data Science&lt;/a&gt; or &lt;a target="_blank" rel="nofollow" href="http://www.openshift.com/DataScienceVideoDemo"&gt;watch this video demo&lt;/a&gt; to see it in action. You can try out the upstream Open Data Hub project yourself at &lt;a target="_blank" rel="nofollow" href="https://opendatahub.io/"&gt;https://opendatahub.io/&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F27%2F4-reasons-youll-love-using-red-hat-openshift-data-science%2F&amp;#38;linkname=4%20reasons%20you%E2%80%99ll%20love%20using%20Red%20Hat%20OpenShift%20Data%20Science" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F27%2F4-reasons-youll-love-using-red-hat-openshift-data-science%2F&amp;#38;linkname=4%20reasons%20you%E2%80%99ll%20love%20using%20Red%20Hat%20OpenShift%20Data%20Science" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F27%2F4-reasons-youll-love-using-red-hat-openshift-data-science%2F&amp;#38;linkname=4%20reasons%20you%E2%80%99ll%20love%20using%20Red%20Hat%20OpenShift%20Data%20Science" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F27%2F4-reasons-youll-love-using-red-hat-openshift-data-science%2F&amp;#38;linkname=4%20reasons%20you%E2%80%99ll%20love%20using%20Red%20Hat%20OpenShift%20Data%20Science" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F27%2F4-reasons-youll-love-using-red-hat-openshift-data-science%2F&amp;#38;linkname=4%20reasons%20you%E2%80%99ll%20love%20using%20Red%20Hat%20OpenShift%20Data%20Science" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F27%2F4-reasons-youll-love-using-red-hat-openshift-data-science%2F&amp;#38;linkname=4%20reasons%20you%E2%80%99ll%20love%20using%20Red%20Hat%20OpenShift%20Data%20Science" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F27%2F4-reasons-youll-love-using-red-hat-openshift-data-science%2F&amp;#38;linkname=4%20reasons%20you%E2%80%99ll%20love%20using%20Red%20Hat%20OpenShift%20Data%20Science" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F27%2F4-reasons-youll-love-using-red-hat-openshift-data-science%2F&amp;#038;title=4%20reasons%20you%E2%80%99ll%20love%20using%20Red%20Hat%20OpenShift%20Data%20Science" data-a2a-url="https://developers.redhat.com/blog/2021/04/27/4-reasons-youll-love-using-red-hat-openshift-data-science/" data-a2a-title="4 reasons you’ll love using Red Hat OpenShift Data Science"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/04/27/4-reasons-youll-love-using-red-hat-openshift-data-science/"&gt;4 reasons you&amp;#8217;ll love using Red Hat OpenShift Data Science&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/tu6B77v5I90" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Red Hat OpenShift Data Science is a managed cloud service built from a curated set of components from the upstream Open Data Hub project. It aims to provide a stable sandbox in which data scientists can develop, train, and test their machine learning (ML) workloads and then deploy results in a container-ready format. This article [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/04/27/4-reasons-youll-love-using-red-hat-openshift-data-science/"&gt;4 reasons you&amp;#8217;ll love using Red Hat OpenShift Data Science&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/04/27/4-reasons-youll-love-using-red-hat-openshift-data-science/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">904257</post-id><dc:creator>Anish Asthana</dc:creator><dc:date>2021-04-27T13:00:47Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/04/27/4-reasons-youll-love-using-red-hat-openshift-data-science/</feedburner:origLink></entry><entry><title>Some more C# 9</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/tuDDdU8JxVU/" /><category term=".NET" /><category term="C#" /><category term="Performance" /><category term="Programming Languages" /><category term=".NET 5" /><category term="C# 9" /><category term="function pointers" /><category term="native interop" /><author><name>Tom Deseyn</name></author><id>https://developers.redhat.com/blog/?p=873937</id><updated>2021-04-27T07:00:26Z</updated><published>2021-04-27T07:00:26Z</published><content type="html">&lt;p&gt;In this final article of our C# 9 series, we’ll look at advanced features related to &lt;a target="_blank" rel="nofollow" href="https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/interop/interoperability-overview"&gt;native interop&lt;/a&gt; and performance in C# 9.&lt;/p&gt; &lt;p&gt;If you missed any of the previous articles in this series, here&amp;#8217;s where you can catch up:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="/blog/2021/03/30/c-9-top-level-programs-and-target-typed-expressions/"&gt;Part 1: C# 9 top-level programs and target-typed expressions&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="/blog/2021/04/06/c-9-pattern-matching/"&gt;Part 2: C# 9 pattern matching&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="/blog/2021/04/13/c-9-new-features-for-methods-and-functions/"&gt;Part 3: C# 9 new features for methods and functions&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="/blog/2021/04/20/c-9-init-accessors-and-records/"&gt;Part 4: C# 9 init accessors and records&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Native-sized integers&lt;/h2&gt; &lt;p&gt;C# 9 introduces language support for native-sized integer types, both signed and unsigned. The existing C# &lt;code&gt;int&lt;/code&gt; and &lt;code&gt;long&lt;/code&gt; types, which map to the underlying &lt;code&gt;System.Int32&lt;/code&gt; and &lt;code&gt;System.Int64&lt;/code&gt; types, have a fixed size of 32 bits and 64 bits, respectively. The new &lt;code&gt;nint&lt;/code&gt; and &lt;code&gt;nuint&lt;/code&gt; types, which map to the existing &lt;code&gt;System.IntPtr&lt;/code&gt; and &lt;code&gt;System.UIntPtr&lt;/code&gt; types, have a size that corresponds to the native machine size. That means they are 32 bit on a 32-bit machine and 64 bit on a 64-bit machine.&lt;/p&gt; &lt;p&gt;C# supports direct arithmetic on &lt;code&gt;nint&lt;/code&gt; and &lt;code&gt;nuint&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;// IntPtr aren't directly usable for arithmetic. IntPtr a = (IntPtr)5; IntPtr b = (IntPtr)6; IntPtr c = new IntPtr((long)a + (long)b); // nint/nuint can be used for arithmetic. nint i = 5; nint j = 6; nint k = i + j; // cast required: int-size may be smaller. int y = (int)i; &lt;/pre&gt; &lt;p&gt;Native integers can be marked &lt;code&gt;const&lt;/code&gt;, but only when the compiler knows that the result won’t overflow on any architecture:&lt;/p&gt; &lt;pre&gt;const nint n = int.MaxValue; // error CS0133: The expression being assigned to 'm' must be constant. const nint m = unchecked(n + 1); &lt;/pre&gt; &lt;p&gt;Native libraries often use machine-sized native integers in their APIs, and the new &lt;code&gt;nint&lt;/code&gt;/&lt;code&gt;nuint&lt;/code&gt; facilitate using such APIs from .NET:&lt;/p&gt; &lt;pre&gt;public unsafe int write(int fd, Span buffer) { fixed(byte* buf = buffer) { return (int)write(fd, buf, (nuint)buffer.Length); } // ssize_t write(int fd, const void *buf, size_t count); // ssize_t, and size_t are signed/unsigned native-size integer types. [DllImport("libc", SetLastError = true)] static extern nint write(int fd, void* buf, nuint count); } &lt;/pre&gt; &lt;h2&gt;Suppressing localsinit&lt;/h2&gt; &lt;p&gt;The &lt;code&gt;localsinit&lt;/code&gt; feature can improve performance. To understand it, have a look at the following method:&lt;/p&gt; &lt;pre&gt;void ReadData() { Span buffer = stackalloc byte[256]; int bytesRead = Read(buffer); buffer = buffer.Slice(0, bytesRead); ProcessData(buffer); } &lt;/pre&gt; &lt;p&gt;Each time this method is called, the runtime ensures that the allocated buffer is zeroed so that the method won&amp;#8217;t read uninitialized data from the stack. The C# compiler emits the &lt;code&gt;.locals init&lt;/code&gt; directive in the method for this to happen.&lt;/p&gt; &lt;p&gt;When performance is critical, it may be desirable to omit this zeroing. C# 9 supports that performance measure through the new &lt;a target="_blank" rel="nofollow" href="https://docs.microsoft.com/en-us/dotnet/api/system.runtime.compilerservices.skiplocalsinitattribute"&gt;&lt;code&gt;SkipLocalsInit&lt;/code&gt;&lt;/a&gt; attribute. This attribute can be applied at the method level, the class level, or even for the entire module:&lt;/p&gt; &lt;pre&gt;// For the entire project. [module: System.Runtime.CompilerServices.SkipLocalsInit] // or, for a specific method. [SkipLocalsInit] void ReadData() { // ... &lt;/pre&gt; &lt;p&gt;If you add this attribute, be careful to initialize variables that are used as &lt;code&gt;out&lt;/code&gt; parameters or whose addresses you pass to another function. Those variables will no longer be zeroed by the compiler:&lt;/p&gt; &lt;pre&gt;[SkipLocalsInit] unsafe void Foo() { int i; // i is not cleared. Bar(&amp;#38;i); } &lt;/pre&gt; &lt;h2&gt;Module initializers&lt;/h2&gt; &lt;p&gt;C# supports &lt;code&gt;static&lt;/code&gt; type constructors, which get called only once when the type is first used. C# 9 makes it possible to add a constructor at the assembly level (more specific: &lt;a target="_blank" rel="nofollow" href="https://docs.microsoft.com/en-us/archive/blogs/junfeng/netmodule-vs-assembly"&gt;module level&lt;/a&gt;). This module initializer runs one time when the module is first used.&lt;/p&gt; &lt;p&gt;Compared to static constructors, a module initializer is more efficient because the runtime doesn’t have to track whether the constructor has been called for each type. Additionally, a module initializer avoids ordering issues that may exist between multiple static constructors.&lt;/p&gt; &lt;p&gt;A method can be marked as a module initializer by adding the &lt;a target="_blank" rel="nofollow" href="https://docs.microsoft.com/en-us/dotnet/api/system.runtime.compilerservices.moduleinitializerattribute"&gt;ModuleInitializer&lt;/a&gt; attribute. The method must be &lt;code&gt;public&lt;/code&gt; or &lt;code&gt;internal&lt;/code&gt;, have a &lt;code&gt;void&lt;/code&gt; return type, and must not accept parameters:&lt;/p&gt; &lt;pre&gt;static void Main(string[] args) { Console.WriteLine("Hello from Main."); } [ModuleInitializer] static internal void MyInitializer() { Console.WriteLine("Hello from initializer!"); } &lt;/pre&gt; &lt;p&gt;Multiple methods can have the &lt;code&gt;ModuleInitializer&lt;/code&gt; attribute. The compiler generates a module initializer that calls all of them.&lt;/p&gt; &lt;h2&gt;Function pointers&lt;/h2&gt; &lt;p&gt;C# has always supported passing methods using &lt;em&gt;delegates&lt;/em&gt;. Delegates are reference types and refer to one or more methods that can be invoked through the delegate:&lt;/p&gt; &lt;pre&gt;Action&amp;#60;string&amp;#62; myDelegate = s =&amp;#62; Console.WriteLine($"Hello 1 {s}"); myDelegate += s =&amp;#62; Console.WriteLine($"Hello 2 {s}"); myDelegate("world!"); &lt;/pre&gt; &lt;p&gt;C# 9 goes a level deeper and allows you to use function pointers directly in C#. Function pointers contain just the address of the function. They may only be used in unsafe blocks.&lt;/p&gt; &lt;p&gt;Function pointers can refer to managed static methods or native functions. For native functions, you can further specify the calling convention if the default is not appropriate. This tells the JIT how arguments need to be passed to the function.&lt;/p&gt; &lt;p&gt;Function pointers are declared using &lt;code&gt;delegate*&lt;/code&gt;. The next example declares three function pointers:&lt;/p&gt; &lt;pre&gt;var pFun1 = (delegate* unmanaged&amp;#60;int, void&amp;#62;)NativeLibrary.GetExport(libHandle, "fun1"); var pFun2 = (delegate* unmanaged[Stdcall]&amp;#60;int, void&amp;#62;)NativeLibrary.GetExport(libHandle, "fun2"); delegate*&amp;#60;int, void&amp;#62; pManagedFunction = &amp;#38;ManagedFunction; &lt;/pre&gt; &lt;p&gt;The first two pointers are &lt;code&gt;unmanaged&lt;/code&gt; and initialized using the &lt;a target="_blank" rel="nofollow" href="https://docs.microsoft.com/en-us/dotnet/api/system.runtime.interopservices.nativelibrary"&gt;NativeLibrary&lt;/a&gt; class. The type parameters are the same as for the &lt;code&gt;Func&lt;/code&gt; delegate: first the argument types, and finally the return type. The pointers declared here accept an &lt;code&gt;int&lt;/code&gt; and have no return type (&lt;code&gt;void&lt;/code&gt;).&lt;/p&gt; &lt;p&gt;The second function pointer specifies the &lt;a target="_blank" rel="nofollow" href="https://docs.microsoft.com/en-us/dotnet/api/system.runtime.compilerservices.callconvstdcall"&gt;Stdcall&lt;/a&gt; calling convention to change from the platform default.&lt;/p&gt; &lt;p&gt;The third function pointer is a managed function pointer. It is assigned using the address-of operator on a static method.&lt;/p&gt; &lt;p&gt;Function calls can be made using the expected call syntax:&lt;/p&gt; &lt;pre&gt;pManagedFunction(10); &lt;/pre&gt; &lt;p&gt;A special case is passing the address of a managed method to a native library. For this, we need to add the &lt;a target="_blank" rel="nofollow" href="https://docs.microsoft.com/en-us/dotnet/api/system.runtime.interopservices.unmanagedcallersonlyattribute"&gt;UnmanagedCallersOnly&lt;/a&gt; attribute to the method. This tells the runtime the method will be called from native code. Such methods must not be called from managed code and can have only &lt;a target="_blank" rel="nofollow" href="https://docs.microsoft.com/en-us/dotnet/framework/interop/blittable-and-non-blittable-types"&gt;blittable&lt;/a&gt; arguments:&lt;/p&gt; &lt;pre&gt;[UnmanagedCallersOnly] static void Log(IntPtr ptr) { Console.Write(Marshal.PtrToStringAnsi(ptr)); } static unsafe void Main(string[] args) { delegate* unmanaged&amp;#60;IntPtr, void&amp;#62; pLog = &amp;#38;Log; nativelib_set_log_function(pLog); ... } &lt;/pre&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In this article, we looked at the new &lt;code&gt;nint&lt;/code&gt; and &lt;code&gt;nuint&lt;/code&gt; native-sized integer types and how they facilitate interop. We learned how the &lt;code&gt;SkipLocalsInit&lt;/code&gt; attribute can avoid the cost of zeroing stack locals. We covered how module initializers allow you to run one or more methods when an assembly or module is first used. And finally, we looked at function pointers and how they can be used with managed and unmanaged functions.&lt;/p&gt; &lt;p&gt;C# 9 can be used with the &lt;a target="_blank" rel="nofollow" href="/blog/2020/12/22/net-5-0-now-available-for-red-hat-enterprise-linux-and-red-hat-openshift/"&gt;.NET 5 SDK&lt;/a&gt;, which is available on &lt;a target="_blank" rel="nofollow" href="/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt;, &lt;a target="_blank" rel="nofollow" href="/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;, &lt;a target="_blank" rel="nofollow" href="http://fedoraloves.net/"&gt;Fedora&lt;/a&gt;, &lt;a target="_blank" rel="nofollow" href="https://dotnet.microsoft.com/download"&gt;Windows, macOS, and other Linux distributions&lt;/a&gt;. For more information on Red Hat&amp;#8217;s support for .NET, see the Red Hat Developer &lt;a target="_blank" rel="nofollow" href="/topics/dotnet"&gt;.NET topic page&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F27%2Fsome-more-c-9%2F&amp;#38;linkname=Some%20more%20C%23%209" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F27%2Fsome-more-c-9%2F&amp;#38;linkname=Some%20more%20C%23%209" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F27%2Fsome-more-c-9%2F&amp;#38;linkname=Some%20more%20C%23%209" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F27%2Fsome-more-c-9%2F&amp;#38;linkname=Some%20more%20C%23%209" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F27%2Fsome-more-c-9%2F&amp;#38;linkname=Some%20more%20C%23%209" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F27%2Fsome-more-c-9%2F&amp;#38;linkname=Some%20more%20C%23%209" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F27%2Fsome-more-c-9%2F&amp;#38;linkname=Some%20more%20C%23%209" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F27%2Fsome-more-c-9%2F&amp;#038;title=Some%20more%20C%23%209" data-a2a-url="https://developers.redhat.com/blog/2021/04/27/some-more-c-9/" data-a2a-title="Some more C# 9"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/04/27/some-more-c-9/"&gt;Some more C# 9&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/tuDDdU8JxVU" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;In this final article of our C# 9 series, we’ll look at advanced features related to native interop and performance in C# 9. If you missed any of the previous articles in this series, here&amp;#8217;s where you can catch up: Part 1: C# 9 top-level programs and target-typed expressions Part 2: C# 9 pattern matching [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/04/27/some-more-c-9/"&gt;Some more C# 9&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/04/27/some-more-c-9/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">873937</post-id><dc:creator>Tom Deseyn</dc:creator><dc:date>2021-04-27T07:00:26Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/04/27/some-more-c-9/</feedburner:origLink></entry><entry><title>Benchmarking transparent versus 1GiB static huge page performance in Linux virtual machines</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Hh8p9GKyNhE/" /><category term="Big Data" /><category term="Linux" /><category term="Performance" /><category term="Linux kernel" /><category term="static huge pages" /><category term="Transparent huge pages" /><author><name>Kevin Buettner</name></author><id>https://developers.redhat.com/blog/?p=821207</id><updated>2021-04-27T07:00:19Z</updated><published>2021-04-27T07:00:19Z</published><content type="html">&lt;p&gt;In this article, I examine the performance of two virtual machines (VMs) using huge pages in the &lt;a target="_blank" rel="nofollow" href="/topics/linux"&gt;Linux&lt;/a&gt; kernel. One VM is configured to use transparent huge pages (THP), which happens by default. The other is configured to use 1GiB static huge pages (SHP), which requires special configuration on the virtualization host and in the virtual machine definition.&lt;/p&gt; &lt;h2&gt;Huge pages in the Linux kernel&lt;/h2&gt; &lt;p&gt;It is one of the Linux kernel&amp;#8217;s responsibilities to manage the translation between virtual and physical addresses for each process. Memory is organized into pages; a page table is consulted when performing virtual-to-physical address translation. In order to avoid repeatedly walking the page table, a cache known as the &lt;a target="_blank" rel="nofollow" href="https://en.wikipedia.org/wiki/Translation_lookaside_buffer"&gt;translation lookaside buffer&lt;/a&gt; (TLB) is utilized to improve performance. The size of the TLB is limited, so on machines with large amounts of physical memory, it can be advantageous to use larger page sizes to reduce the number of TLB misses.&lt;/p&gt; &lt;p&gt;On the x86-64 architecture, the default page size is 4KiB, though larger page sizes of 2MiB and 1GiB are both supported. The 1GiB huge pages are supported only on processors with the &lt;code&gt;pdpe1gb&lt;/code&gt; CPU flag.&lt;/p&gt; &lt;p&gt;QEMU/KVM, by default, attempts to allocate virtual machine memory using the transparent huge page mechanism, which uses 2MiB pages. Larger 1GiB pages may be allocated to the virtual machine if both the virtualization host and virtual machine have been configured to use them. These 1GiB huge pages may be allocated either statically at boot time or dynamically at runtime. I ran my experiments using static boot-time allocation. Dynamic allocation is somewhat more complicated; &lt;a target="_blank" rel="nofollow" href="https://wiki.archlinux.org/index.php/PCI_passthrough_via_OVMF#Dynamic_huge_pages"&gt;other resources&lt;/a&gt; should be consulted if you want to use dynamic, non-transparent huge page allocation. It should also be understood that 2MiB pages may be statically allocated, but doing so is not as compelling because the transparent huge page mechanism already uses this page size.&lt;/p&gt; &lt;h2&gt;1GiB static huge page configuration on the virtualization host&lt;/h2&gt; &lt;p&gt;On the virtualization host, 1GiB huge pages are reserved by adding the following parameters to the Linux kernel command line:&lt;/p&gt; &lt;pre&gt;hugepagesz=1G hugepagesz=1G hugepages=&lt;em&gt;N&lt;/em&gt;&lt;/pre&gt; &lt;p&gt;You would, of course, replace &lt;em&gt;N&lt;/em&gt; with some suitable number. For instance, on my virtualization host, I&amp;#8217;m using &lt;code&gt;hugepages=48&lt;/code&gt;. This, in conjunction with the other command-line parameters, allocates 48GiB of memory for use as 1GiB static huge pages. I didn&amp;#8217;t actually require this many huge pages for my experiments. I wanted to test using a scenario that I might use in my daily work, where I have several virtual machines in constant use.&lt;/p&gt; &lt;p&gt;Kernel command-line parameters can be set using &lt;code&gt;grubby&lt;/code&gt; as described for &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/managing_monitoring_and_updating_the_kernel/configuring-kernel-command-line-parameters_managing-monitoring-and-updating-the-kernel"&gt;Red Hat Enterprise Linux&lt;/a&gt; (RHEL) or &lt;a target="_blank" rel="nofollow" href="https://docs.fedoraproject.org/en-US/Fedora/23/html/System_Administrators_Guide/sec-Configuring_GRUB_2_Using_the_grubby_Tool.html"&gt;Fedora&lt;/a&gt;. Kernel command-line arguments can also be added to &lt;code&gt;GRUB_CMDLINE_LINUX&lt;/code&gt; in &lt;code&gt;/etc/default/grub&lt;/code&gt; and then enabled by running &lt;code&gt;grub2-mkconfig&lt;/code&gt; as appropriate for your installation. I used this latter approach for configuring the virtualization host in my experiments.&lt;/p&gt; &lt;h3&gt;Huge page configuration for virtual machines&lt;/h3&gt; &lt;p&gt;As noted earlier, QEMU attempts to use transparent huge pages to allocate memory for virtual machines. Non-transparent huge pages, either static or dynamic, may instead be used by making changes to the XML definition for the machine. All you have to do is to add the following lines to the libvirt domain defining the machine:&lt;/p&gt; &lt;pre&gt;&amp;#60;memoryBacking&amp;#62; &amp;#60;hugepages/&amp;#62; &amp;#60;/memoryBacking&amp;#62; &lt;/pre&gt; &lt;p&gt;For my experiments, I made the change via the &lt;strong&gt;XML&lt;/strong&gt; tab in &lt;code&gt;virt-manager&lt;/code&gt;. It is also possible to use the &lt;code&gt;virsh edit &lt;em&gt;vmname&lt;/em&gt;&lt;/code&gt; command to make this change.&lt;/p&gt; &lt;h3&gt;Virtualization host&lt;/h3&gt; &lt;p&gt;The virtualization host that I used for my experiments has 128GiB of RAM with a 16-core (32 thread) AMD Ryzen Threadripper 2950X processor. This processor has a base clock speed of 3.5GHz and a maximum boost clock speed of 4.4GHz. Total L1, L2, and L3 cache sizes are 1.5MiB, 8MiB, and 32MiB, respectively. The processor was not overclocked, but I did use the RAM&amp;#8217;s XMP profile (which is technically a type of overclocking) in order to utilize the RAM&amp;#8217;s advertised speed. Table 1 summarizes the specifications for the host.&lt;/p&gt; &lt;table align="center"&gt; &lt;caption&gt;&lt;strong&gt;Table 1: Specifications for the virtualization host&lt;/strong&gt;&lt;/caption&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Processor&lt;/td&gt; &lt;td&gt;AMD Ryzen Threadripper 2950X&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Memory size&lt;/td&gt; &lt;td&gt;128GiB&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Memory details&lt;/td&gt; &lt;td&gt;8x16GB Corsair Vengeance LPX 2666MHz (PC4 21300)&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Motherboard&lt;/td&gt; &lt;td&gt;ASRock X399 Professional Gaming&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;OS&lt;/td&gt; &lt;td&gt;Fedora 32&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Linux kernel version&lt;/td&gt; &lt;td&gt;5.7.17-200.fc32.x86_64&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;QEMU version&lt;/td&gt; &lt;td&gt;4.2.1-1.fc32.x86_64&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h3&gt;Virtual machines&lt;/h3&gt; &lt;p&gt;I created a virtual machine on which I installed Fedora 32 along with all the packages that I needed for my experiments. Next, I created a second virtual machine by cloning the disk image and machine definition from the first. Finally, I changed the definition of what would become the 1GiB huge page VM to use the following code as part of the machine definition:&lt;/p&gt; &lt;pre&gt;&amp;#60;memoryBacking&amp;#62; &amp;#60;hugepages/&amp;#62; &amp;#60;/memoryBacking&amp;#62; &lt;/pre&gt; &lt;p&gt;Table 2 summarizes the test VM configuration.&lt;/p&gt; &lt;table align="center"&gt; &lt;caption&gt;&lt;strong&gt;Table 2: Configuration of the virtual machines&lt;/strong&gt;&lt;/caption&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;/td&gt; &lt;td&gt;THP&lt;/td&gt; &lt;td&gt;1GiB SHP&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Cores&lt;/td&gt; &lt;td&gt;14&lt;/td&gt; &lt;td&gt;14&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Memory size&lt;/td&gt; &lt;td&gt;12GiB&lt;/td&gt; &lt;td&gt;12GiB&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;OS&lt;/td&gt; &lt;td&gt;Fedora 32&lt;/td&gt; &lt;td&gt;Fedora 32&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Linux kernel version&lt;/td&gt; &lt;td&gt;5.7.7-200.fc32.x86_64&lt;/td&gt; &lt;td&gt;5.7.7-200.fc32.x86_64&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Additional configuration&lt;/td&gt; &lt;td&gt;None&lt;/td&gt; &lt;td&gt;&lt;code&gt;&amp;#60;memoryBacking&amp;#62;&amp;#60;hugepages/&amp;#62;&amp;#60;/memoryBacking&amp;#62;&lt;/code&gt; added to XML&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;I wanted to avoid over-provisioning the virtualization host, so I allocated only 14 cores to each virtual machine. The virtualization host provides 32 virtual cores. Allocating 14 cores to each VM means that they collectively use 28 cores, leaving 4 cores free for the virtualization host.&lt;/p&gt; &lt;p&gt;With regard to RAM size, 12GiB is more than enough for each of the benchmarks that I ran. Swap space was provisioned, but was never needed.&lt;/p&gt; &lt;h2&gt;Benchmarks&lt;/h2&gt; &lt;p&gt;I ran many trials of three separate benchmarks on each machine. For each benchmark, I appended either time or benchmark-related output to a benchmark-specific file, which was later analyzed. Prior to this testing, I ran 40 to 50 trials for each benchmark by hand, recording the results in a spreadsheet. However, there was a remarkable degree of variability from one run to the next, which was borne out by a fairly large standard deviation for these early trials. Therefore, in order to obtain statistically meaningful results, a much larger number of trials would have to be run. A back-of-the-envelope calculation for build testing for the GNU Project debugger (GDB) showed that at least 6,000 samples would be needed. In the end, I ran four times this number of trials per machine, resulting in a suitably small margin of error using a 99.99% confidence interval.&lt;/p&gt; &lt;h3&gt;Benchmark: Sysbench memory&lt;/h3&gt; &lt;p&gt;According to its man page, Sysbench &amp;#8220;is a modular, cross-platform and multi-threaded benchmark tool for evaluating OS parameters that are important for a system running a database under intensive load.&amp;#8221; For database testing, it can test both MySQL and PostgreSQL. But it can also test lower-level system attributes, including &lt;code&gt;fileio&lt;/code&gt;, &lt;code&gt;cpu&lt;/code&gt;, &lt;code&gt;memory&lt;/code&gt;, &lt;code&gt;threads&lt;/code&gt;, and &lt;code&gt;mutexes&lt;/code&gt;. I was interested in testing memory performance, so I used Sysbench&amp;#8217;s memory test.&lt;/p&gt; &lt;p&gt;The package name and version that I used for testing was &lt;code&gt;sysbench-1.0.17-4.fc32.x86_64&lt;/code&gt;. I experimented with different command-line parameters, settling on this command to use as a benchmark:&lt;/p&gt; &lt;pre&gt;$ sysbench memory --memory-block-size=64M --memory-total-size=4096G --time=500 --threads=14 run&lt;/pre&gt; &lt;p&gt;I ran this benchmark concurrently, in a loop, on each virtual machine. During my early investigations, I did notice that results would likely be significantly faster if only one virtual machine ran the benchmark at a time. Although it might have been interesting to compare the results of running the benchmark on only one machine at a time, I was more interested in what would happen when both machines had a significant concurrent load. Table 3 summarizes the results.&lt;/p&gt; &lt;table align="center"&gt; &lt;caption&gt;&lt;strong&gt;Table 3: Sysbench memory use&lt;/strong&gt;&lt;/caption&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;/td&gt; &lt;td&gt;THP&lt;/td&gt; &lt;td&gt;1GiB SHP&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Mean&lt;/td&gt; &lt;td&gt;131.55 secs&lt;/td&gt; &lt;td&gt;128.34 secs&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Samples&lt;/td&gt; &lt;td&gt;5000&lt;/td&gt; &lt;td&gt;5000&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Standard deviation&lt;/td&gt; &lt;td&gt;4.38 secs&lt;/td&gt; &lt;td&gt;4.2 secs&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Min&lt;/td&gt; &lt;td&gt;102.96 secs&lt;/td&gt; &lt;td&gt;101.99 secs&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Max&lt;/td&gt; &lt;td&gt;148.28 secs&lt;/td&gt; &lt;td&gt;144.95 secs&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Confidence level&lt;/td&gt; &lt;td&gt;99.99%&lt;/td&gt; &lt;td&gt;99.99%&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Margin of error&lt;/td&gt; &lt;td&gt;0.24 secs&lt;/td&gt; &lt;td&gt;0.23 secs&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;On average, the 1GiB SHP virtual machine is faster than the THP virtual machine by 3.21 seconds or 2.4%. Note, too, that the 1GiB SHP VM had lower minimum and maximum times than the THP VM. A comparison of the means is summarized by the bar chart in Figure 1. The error bars show the margin of error for a 99.99% confidence level.&lt;/p&gt; &lt;div id="attachment_823597" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fb43aab9583b.png"&gt;&lt;img aria-describedby="caption-attachment-823597" class="wp-image-823597" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fb43aab9583b.png" alt="In Sysbench memory use, the 1GiB SHP VM uses less memory than the THP VM." width="640" height="676" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-823597" class="wp-caption-text"&gt;Figure 1: Sysbench memory use in a comparison of VMs.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Benchmark: iperf3&lt;/h3&gt; &lt;p&gt;The &lt;code&gt;iperf3&lt;/code&gt; tests network throughput. The tool is typically used between different physical interfaces on machines in a network; this is not only to test throughput between machines, but also to check for problems. For instance, on my local network, I once used &lt;code&gt;iperf3&lt;/code&gt; to identify a problem in which a particular network interface locked up when jumbo frames were enabled on all interfaces (and on the network switch).&lt;/p&gt; &lt;p&gt;&lt;code&gt;iperf3&lt;/code&gt; can also be used to check throughput between a virtual machine and its virtualization host. As described later, the GDB-build benchmarking I did took place over NFS, so I thought it would be good to know how much network performance impacted any performance differences for that benchmark.&lt;/p&gt; &lt;p&gt;I used the &lt;code&gt;iperf3-3.7-3.fc32.x86_64&lt;/code&gt; package both on the virtualization host and on each virtual machine.&lt;/p&gt; &lt;p&gt;On the virtualization host, the following command is run; it starts &lt;code&gt;iperf3&lt;/code&gt; as a server that runs until interrupted:&lt;/p&gt; &lt;pre&gt;iperf3 -s&lt;/pre&gt; &lt;p&gt;On each virtual machine, &lt;code&gt;iperf3&lt;/code&gt; is run as a client that connects to the server:&lt;/p&gt; &lt;pre&gt;iperf3 -c &lt;em&gt;virtualization-host&lt;/em&gt;&lt;/pre&gt; &lt;p&gt;Output from each run was appended to a file that was later analyzed. Specifically, the sender&amp;#8217;s bandwidth was extracted for analysis. Also, unlike the testing performed for the other benchmarks, &lt;code&gt;iperf3&lt;/code&gt; testing ran on only one virtual machine at a time. (Starting the server as shown earlier allows only one client connection at a time.) Table 4 summarizes the results.&lt;/p&gt; &lt;table align="center"&gt; &lt;caption&gt;&lt;strong&gt;Table 4: iperf3 results&lt;/strong&gt;&lt;/caption&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;/td&gt; &lt;td&gt;THP&lt;/td&gt; &lt;td&gt;1GiB SHP&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Mean&lt;/td&gt; &lt;td&gt;29.74 Gbits/sec&lt;/td&gt; &lt;td&gt;29.85 Gbits/sec&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Samples&lt;/td&gt; &lt;td&gt;37000&lt;/td&gt; &lt;td&gt;37000&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Standard deviation&lt;/td&gt; &lt;td&gt;1.58 Gbits/sec&lt;/td&gt; &lt;td&gt;1.4 Gbits/sec&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Min&lt;/td&gt; &lt;td&gt;16.2 Gbits/sec&lt;/td&gt; &lt;td&gt;18.7 Gbits/sec&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Max&lt;/td&gt; &lt;td&gt;33 Gbits/sec&lt;/td&gt; &lt;td&gt;32.8 Gbits/sec&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Confidence level&lt;/td&gt; &lt;td&gt;99.99%&lt;/td&gt; &lt;td&gt;99.99%&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Margin of error&lt;/td&gt; &lt;td&gt;0.03 Gbits/sec&lt;/td&gt; &lt;td&gt;0.03 Gbits/sec&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;This benchmark shows a less compelling result than the Sysbench memory benchmark, with only a 0.11 gigabit per second (or 0.4%) advantage for the 1GiB SHP VM over the THP VM. It&amp;#8217;s interesting, too, that the THP VM shows a markedly lower minimum (indicating poor performance) but also the highest maximum (indicating better performance). I will note, however, that the 33 gigabit per second maximum was achieved somewhat late during testing. I would not be surprised to see the 1GiB SHP VM also achieve an identical or better maximum result if even more tests were run.&lt;/p&gt; &lt;p&gt;Figure 2 shows the difference in means, with error bars representing a 99.99% confidence level.&lt;/p&gt; &lt;div id="attachment_823667" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fb4429bc72b1.png"&gt;&lt;img aria-describedby="caption-attachment-823667" class="wp-image-823667 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fb4429bc72b1-1024x577.png" alt="In the iperf3 results, the 1GiB SHP VM has a higher bit transfer rate than the THP VM." width="640" height="361" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fb4429bc72b1-1024x577.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fb4429bc72b1-300x169.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fb4429bc72b1-768x433.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fb4429bc72b1.png 1200w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-823667" class="wp-caption-text"&gt;Figure 2: iperf3 results in a VM comparison.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Benchmark: GDB build&lt;/h3&gt; &lt;p&gt;I work on GDB for my day job, so I&amp;#8217;m interested in ways to achieve faster builds of this software project. I was curious to see whether a virtual machine configured to use 1GiB huge pages would build GDB faster than a virtual machine using transparent huge pages.&lt;/p&gt; &lt;p&gt;However, I&amp;#8217;m also interested in convenience: I keep GDB source trees on NFS mounted storage and do nearly all builds on NFS mounted storage, as well. I know for a fact that I can achieve faster build times by building on &amp;#8220;local&amp;#8221; storage. However, I find this less convenient because building on local storage means that build trees are distributed across the local storage of a number of machines, some of which may not be running or even still in existence. So in this case, even though building and testing GDB is faster using local storage, I opt to keep my build trees centralized on an NFS server. For many of the virtual machines that I run, this server is also the virtualization host.&lt;/p&gt; &lt;p&gt;With that configuration in mind, I devised a GDB build benchmark to closely mimic the builds that I actually do as a GDB developer: Both source and build trees are located on an NFS-mounted file system in which the virtualization host is also the NFS server.&lt;/p&gt; &lt;p&gt;After running a suitable top-level configure command, I directed the output of the following &lt;code&gt;time&lt;/code&gt; command into a host-specific file for later analysis:&lt;/p&gt; &lt;pre&gt;time make -j12&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;time&lt;/code&gt; command outputs three time values for each command that it times. For this experiment, I was interested only in wall clock (real) time because, as a developer, that&amp;#8217;s the amount of time that I need to wait for the build to finish.&lt;/p&gt; &lt;p&gt;Table 5 summarizes the results.&lt;/p&gt; &lt;table align="center"&gt; &lt;caption&gt;&lt;strong&gt;Table 5: GDB build times&lt;/strong&gt;&lt;/caption&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;/td&gt; &lt;td&gt;THP&lt;/td&gt; &lt;td&gt;1GiB SHP&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Mean&lt;/td&gt; &lt;td&gt;147.08 sec&lt;/td&gt; &lt;td&gt;145.43 sec&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Samples&lt;/td&gt; &lt;td&gt;24000&lt;/td&gt; &lt;td&gt;24000&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Standard deviation&lt;/td&gt; &lt;td&gt;14.53 sec&lt;/td&gt; &lt;td&gt;14.42 sec&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Min&lt;/td&gt; &lt;td&gt;102.31 sec&lt;/td&gt; &lt;td&gt;101.25 sec&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Max&lt;/td&gt; &lt;td&gt;592.13 sec&lt;/td&gt; &lt;td&gt;562.92 sec&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Confidence level&lt;/td&gt; &lt;td&gt;99.99%&lt;/td&gt; &lt;td&gt;99.99%&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Margin of error&lt;/td&gt; &lt;td&gt;0.36 sec&lt;/td&gt; &lt;td&gt;0.36 sec&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;Table 5 shows that, on average, the 1GiB SHP virtual machine finished its GDB builds 1.65 seconds or 1.1% faster than the THP virtual machine. Both minimum and maximum times were better for the static huge page virtual machine. The maximum times for both machines are really high though; I&amp;#8217;ll have more to say about that later.&lt;/p&gt; &lt;p&gt;Figure 3 summarizes the difference in means, along with error bars for a 99.99% confidence level:&lt;/p&gt; &lt;div id="attachment_823807" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fb451c0f0e60.png"&gt;&lt;img aria-describedby="caption-attachment-823807" class="wp-image-823807" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fb451c0f0e60.png" alt="In building GDB, the 1GiB SHP VM is faster than the THP VM." width="640" height="668" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-823807" class="wp-caption-text"&gt;Figure 3: Time required for GDB builds in a comparison of VMs.&lt;/p&gt;&lt;/div&gt; &lt;h4&gt;Do GDB build time samples represent a normal distribution?&lt;/h4&gt; &lt;p&gt;Statistical formulae for calculating standard error and margin of error assume that the collected data fit a bell curve shape indicating a normal distribution. I became concerned that the GDB build time samples might not be &amp;#8220;normal&amp;#8221; because the maximum times for the GDB builds are over 22σ (that is, 22 standard deviations) away from the mean. If these data represent a normal distribution, this is &lt;em&gt;extremely&lt;/em&gt; unlikely. For the THP tests, six samples were at least +6σ from the mean and 139 samples were at least +3σ from the mean. For the 1GiB SHP tests, 11 samples were at least +6σ  from the mean and 131 samples were at least +3σ from the mean. I am less concerned about the minimum times because all of them are pretty close to within -3σ from the mean.&lt;/p&gt; &lt;p&gt;I wanted to see what the data looked like visually, so I created histograms showing the data for each machine. Figures 4 and 5 show the histograms.&lt;/p&gt; &lt;div id="attachment_823827" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fb454151d9ec.png"&gt;&lt;img aria-describedby="caption-attachment-823827" class="wp-image-823827 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fb454151d9ec-1024x632.png" alt="Times required for GDB builds on the THP VM." width="640" height="395" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fb454151d9ec-1024x632.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fb454151d9ec-300x185.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fb454151d9ec-768x474.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fb454151d9ec.png 1200w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-823827" class="wp-caption-text"&gt;Figure 4: Times required for GDB builds on the THP VM.&lt;/p&gt;&lt;/div&gt; &lt;div id="attachment_823837" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fb4543e6a5e5.png"&gt;&lt;img aria-describedby="caption-attachment-823837" class="wp-image-823837 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fb4543e6a5e5-1024x632.png" alt="Times required for GDB builds on the 1GiB SHP VM." width="640" height="395" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fb4543e6a5e5-1024x632.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fb4543e6a5e5-300x185.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fb4543e6a5e5-768x474.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fb4543e6a5e5.png 1200w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-823837" class="wp-caption-text"&gt;Figure 5: Times required for GDB builds on the 1GiB SHP VM.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Except for the outliers at each end, these histograms look fairly &amp;#8220;normal&amp;#8221; to me. I don&amp;#8217;t have enough knowledge of statistics to say whether the outliers present a problem for the use of statistical formulae to calculate the margin of error.&lt;/p&gt; &lt;h4&gt;Why is the standard deviation so large?&lt;/h4&gt; &lt;p&gt;The &lt;code&gt;-j&lt;/code&gt; flag of Make causes portions of the GDB build to run in parallel. I used &lt;code&gt;-j12&lt;/code&gt;, which means that up to 12 different Make-related tasks might run simultaneously. I occasionally watched &lt;code&gt;virt-manager&lt;/code&gt;&amp;#8216;s CPU usage graph as builds were taking place and noticed that, although there were periods of time when all cores were utilized, much of the time they were not. The reason is that Make must wait for various dependencies to complete prior to being able to start another stage of the build. This was most obvious when the compilation of C or C++ files was finishing up prior to running the linker on a group of object files to form an executable or shared object. Running &lt;code&gt;configure&lt;/code&gt; scripts for the various subdirectories also has a serializing effect on the build.&lt;/p&gt; &lt;p&gt;During the fast builds, I think it&amp;#8217;s likely that longer or harder compilations were fortuitously assigned to cores that could achieve a higher boost clock at that moment. If everything meshes just right, Make doesn&amp;#8217;t need to wait very long before starting the linker. Likewise, a slow build might do just the opposite.&lt;/p&gt; &lt;p&gt;I don&amp;#8217;t know why the really slow builds—the outliers mentioned earlier—were as slow as they were. Collecting 24,000 samples per machine for the GDB build benchmark alone took over 40 days. The &lt;code&gt;iperf3&lt;/code&gt; and &lt;code&gt;sysbench memory&lt;/code&gt; benchmarks required several additional weeks of testing. During this entire time, the virtualization host and each virtual machine were entirely dedicated to benchmark testing and were used for no other purpose. That said, there are occasional system-related tasks—such as checking for software updates—that occur on a regular basis. I didn&amp;#8217;t disable any of these tasks, nor have I looked at their resource consumption. I still find it astonishing that several of the GDB builds, in which the mean build time is only a minute and 20-some seconds, took over nine minutes to complete!&lt;/p&gt; &lt;p&gt;During my early investigations, I attempted to reduce the standard deviation by making BIOS changes to either underclock or overclock the CPU. I had thought that doing so might cause all cores to run at the same speed, which in turn might result in a more deterministic build behavior. My attempts at disabling the CPU boost were unsuccessful, though, and in hindsight, this was probably for the best.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Each benchmark shows a performance improvement when using 1GiB static huge pages. The &lt;code&gt;iperf3&lt;/code&gt; benchmark showed a tiny 0.4% improvement, while &lt;code&gt;sysbench memory&lt;/code&gt; showed a more substantial 2.4% boost in performance. GDB builds were in the middle with a 1.1% improvement in performance.&lt;/p&gt; &lt;p&gt;For a software developer doing dozens of builds per day, that 1.1% improvement from using static huge pages isn&amp;#8217;t especially exciting, since it decreases the build time by only roughly 1.7 seconds for a two-minute and twenty-some-second build. However, a server dedicated to building software continuously will get more work done per day. Using the hardware and software configuration described in this post, nearly seven additional GDB builds per day can be completed. For a backlogged build machine, this could provide a small, but still welcome, performance improvement.&lt;/p&gt; &lt;p&gt;A drawback of allocating static huge pages at boot time is that they cannot be used for non-huge page allocations. These huge pages can be effectively used if one or more virtual machines are constantly running. On the other hand, if virtual machines (or other applications that might use huge pages) run only occasionally, reserving and not using huge pages means that this memory is unavailable for other purposes. In this case, it is probably better to use the transparent huge page mechanism instead.&lt;/p&gt; &lt;p&gt;I started these experiments because I had seen static huge pages mentioned in the performance tuning sections of several virtualization guides. It wasn&amp;#8217;t clear to me, however, what performance benefits I might see. Now that I know there is a slight performance benefit for my use case, I plan to allocate static huge pages for virtual machines that I plan to have constantly running. The remainder will continue to use transparent huge pages.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F27%2Fbenchmarking-transparent-versus-1gib-static-huge-page-performance-in-linux-virtual-machines%2F&amp;#38;linkname=Benchmarking%20transparent%20versus%201GiB%20static%20huge%20page%20performance%20in%20Linux%20virtual%20machines" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F27%2Fbenchmarking-transparent-versus-1gib-static-huge-page-performance-in-linux-virtual-machines%2F&amp;#38;linkname=Benchmarking%20transparent%20versus%201GiB%20static%20huge%20page%20performance%20in%20Linux%20virtual%20machines" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F27%2Fbenchmarking-transparent-versus-1gib-static-huge-page-performance-in-linux-virtual-machines%2F&amp;#38;linkname=Benchmarking%20transparent%20versus%201GiB%20static%20huge%20page%20performance%20in%20Linux%20virtual%20machines" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F27%2Fbenchmarking-transparent-versus-1gib-static-huge-page-performance-in-linux-virtual-machines%2F&amp;#38;linkname=Benchmarking%20transparent%20versus%201GiB%20static%20huge%20page%20performance%20in%20Linux%20virtual%20machines" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F27%2Fbenchmarking-transparent-versus-1gib-static-huge-page-performance-in-linux-virtual-machines%2F&amp;#38;linkname=Benchmarking%20transparent%20versus%201GiB%20static%20huge%20page%20performance%20in%20Linux%20virtual%20machines" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F27%2Fbenchmarking-transparent-versus-1gib-static-huge-page-performance-in-linux-virtual-machines%2F&amp;#38;linkname=Benchmarking%20transparent%20versus%201GiB%20static%20huge%20page%20performance%20in%20Linux%20virtual%20machines" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F27%2Fbenchmarking-transparent-versus-1gib-static-huge-page-performance-in-linux-virtual-machines%2F&amp;#38;linkname=Benchmarking%20transparent%20versus%201GiB%20static%20huge%20page%20performance%20in%20Linux%20virtual%20machines" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F27%2Fbenchmarking-transparent-versus-1gib-static-huge-page-performance-in-linux-virtual-machines%2F&amp;#038;title=Benchmarking%20transparent%20versus%201GiB%20static%20huge%20page%20performance%20in%20Linux%20virtual%20machines" data-a2a-url="https://developers.redhat.com/blog/2021/04/27/benchmarking-transparent-versus-1gib-static-huge-page-performance-in-linux-virtual-machines/" data-a2a-title="Benchmarking transparent versus 1GiB static huge page performance in Linux virtual machines"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/04/27/benchmarking-transparent-versus-1gib-static-huge-page-performance-in-linux-virtual-machines/"&gt;Benchmarking transparent versus 1GiB static huge page performance in Linux virtual machines&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Hh8p9GKyNhE" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;In this article, I examine the performance of two virtual machines (VMs) using huge pages in the Linux kernel. One VM is configured to use transparent huge pages (THP), which happens by default. The other is configured to use 1GiB static huge pages (SHP), which requires special configuration on the virtualization host and in the [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/04/27/benchmarking-transparent-versus-1gib-static-huge-page-performance-in-linux-virtual-machines/"&gt;Benchmarking transparent versus 1GiB static huge page performance in Linux virtual machines&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/04/27/benchmarking-transparent-versus-1gib-static-huge-page-performance-in-linux-virtual-machines/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">821207</post-id><dc:creator>Kevin Buettner</dc:creator><dc:date>2021-04-27T07:00:19Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/04/27/benchmarking-transparent-versus-1gib-static-huge-page-performance-in-linux-virtual-machines/</feedburner:origLink></entry></feed>
